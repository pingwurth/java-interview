# 面试题-微服务

#### 分布式和微服务的区别是什么？

分布式是把一个集中式系统拆分成多个系统，每一个系统单独对外提供部分功能，整个分布式系统整体对外提供一整套服务。对于访问分布式系统的用户来说，感知上就像访问一台计算机一样。

**而分布式架构的具体实现有很多种，这其中包括了C/S架构、P2P架构、SOA架构、微服务架构、Serverless架构等。**

**所以，微服务架构是分布式架构的一种。**

> C/S 架构
>
> C/S架构，就是 Client/Server (C/S) 架构，在这种架构中，客户端应用程序通过网络连接到一个或多个服务器，并向服务器发送请求以获取服务或数据。服务器负责处理客户端的请求并返回相应的结果。这种架构常见于 Web 应用程序、数据库系统等。
>
> 在传统的 C/S 模式下，我们想要下载一个 20G 的电影，我们需要找到一个提供该电影资源的网站，然后连接网站的服务器连续下载。也就是要从文件原始位置开始下载这 20G 的完整数据。
>
> 这种下载方式有什么缺点？
>
> 1、首先这种方式比较依赖服务器的可用性，也就是说，如果服务器挂了，那么就电影的下载不得不终止。
> 2、如果想要下载电影的人数增多，网站的带宽就会成为瓶颈，就会导致大家下载速度下降，甚至有人无法下载。
> 3、由于所有资源都通过服务器端输出，别人想要攻击的话也相对方便，只要攻击服务器就可以了。



> P2P 架构
>
> P2P，是 Peer-To-Peer 的简称，翻译成"对等网络"或者"点对点网络"。P2P是一种分布式网络，网络的参与者共享他们所拥有的一部分硬件资源（处理能力、存储能力、网络连接能力、打印机等），这些共享资源需要由网络提供服务和内容，能被其它对等节点(Peer)直接访问而无需经过中间实体。在此网络中的参与者既是资源（服务和内容）提供者（Server），又是资源（服务和内容）获取者（Client）。
>
> 正是因为 C/S 模式存在着这些问题，于是 P2P 就应运而生。
> P2P 打破了传统的 C/S 模式，在网络中的每个结点的地位都是对等的。每个结点既充当服务器，为其他结点提供服务，同时也享用其他结点提供的服务。
>
> 在 P2P 模式下，如果有多个人想要下载同一个电影的话，大家就可以不必分别从服务器下载完整的 20G 的电影。
>
> 由于采用了 P2P 模式，那么每一个用户就可以既充当客户端又可以充当服务器。
>
> 如果 4 个人同时下载 20G 电影，那么 4 个人分别各自下载了不一样的部分，然后在下载的同时进行相互传送。
>
> 这样大家一边从服务器下载得到数据，一边从别的下载的人那里得到数据，就比单一从服务器下载来得快。
>
> P2P 架构具有非中心化、可扩展、高性能、高性价比等优点。
>
> P2P 架构在很多方面都有应用，比如我们常用的很多下载软件，如 T、迅雷等。



> Servless 架构
>
> Servless，即无服务架构，是一种将应用程序逻辑交给云服务提供商管理的架构形式。
>
> 应用程序以函数的形式运行，通过事件驱动的方式触发。无服务架构将基础设施管理的责任交给云平台，开发人员可以专注于业务逻辑。无服务架构适用于快速开发、弹性扩展和按需计费的场景。



#### 什么是微服务架构？优势？特点？

> https://developer.aliyun.com/article/2764

微服务（Microservices）是一种软件架构风格，用于构建复杂的应用程序。它将一个大型的应用程序拆分成一组小型、独立的服务单元，每个服务单元都可以独立部署、运行和扩展。每个微服务都专注于执行一个特定的业务功能，并通过轻量级的通信机制（如HTTP、RPC、MQ等）来相互调用。

微服务的目的是有效的拆分应用，实现敏捷开发和部署 。

比如把一个原来中心化的商城服务，拆分成产品服务、订单服务及用户服务，每一个服务把功能内聚，系统间通过远程调用解耦。实现高内聚低耦合。

并且每一个服务都可以独立的提供子服务。并且他们有自己的应用、自己的存储，是独立的，互不影响的。

而且，拆分后的不同的服务可以使用不同的技术栈，因为它们是独立的。这使得团队可以选择最适合其需求的技术来构建服务。

并且做了服务拆分之后，也能提升迭代速度，至少产品服务的变更不会对订单服务有任何影响。大家可以并行开发，快速迭代。



#### SOA和微服务之间的主要区别是什么？

其实 SOA 和微服务就是差不多的。

SOA 关注的是服务重用，微服务在关注服务重用的同时，也同时关注快速交付；

微服务不再强调传统 SOA 架构里面比较重的 ESB 企业服务总线。微服务把所有的“思考”逻辑包括路由、消息解析等放在服务内部，去掉一个大一统的 ESB，服务间轻通信，是比 SOA 更彻底的拆分。（可以看看这篇文章，我觉得写的挺好的：微服务（Microservice）那点事）。



#### 面向服务的架构

面向服务架构（Service-Oriented Architecture，SOA）又称“面向服务的体系结构”，是 Gartner 于20世纪90年代中期提出的面向服务架构的概念。

面向服务架构，从语义上说，它与面向过程、面向对象、面向组件一样，是一种软件组建及开发的方式。与以往的软件开发、架构模式一样，SOA 只是一种体系、一种思想，而不是某种具体的软件产品。

> 这里，我们通过一个例子来解释一下到底什么是 SOA？如何做到 SOA？

**什么是 SOA**

SOA 也可以说是一种是设计原则（模式），那么它包含哪些内容呢？事实上，这方面并没有最标准的答案，多数是遵从著名 SOA 专家 Thomas Erl 的归纳：

标准化的服务契约 Standardized service contract
服务的松耦合 Service loose coupling
服务的抽象 Service abstraction
服务的可重用性 Service reusability
服务的自治性 Service autonomy
服务的无状态性 Service statelessness
服务的可发现性 Service discoverability
服务的可组合性 Service composability

这些原则总的来说要达到的目的是：提高软件的重用性，减少开发和维护的成本，最终增加一个公司业务的敏捷度。

既然是面向服务的架构，那么我们就先来定义一个服务，

```java
public interface Echo {
    String echo(String text);
}

public class EchoImpl implements Echo {
    public String echo(String text) {
        return text;
    }
}
```

**实现 SOA**

修改一下上面的 Echo，添加 Java EE 的 @WebServices 注解

```java
@WebServices
public class EchoImpl implements Echo {
    public String echo(String text) {
        return text;
    }
}
```

现在将 Echo 发布为 Java WebServices，并由底层框架自动生成WSDL来作为标准化的服务契约，这样就能与远程的各种语言和平台互操作了，较好的解决了上面提到的松耦合和可重用的问题。按照一般的理解，Echo 似乎就成为比较理想的 SOA service 了。

使用 WebServices 只是一种相对简单的方案，SOA 的最常见的解决方案是 SCA，其次还有 JBI，BPEL 等。ESB 是 SCA 思想实现的基础设施。ESB 主要作用是集中注册发布服务，为服务与传输协议之间解耦。关于 SCA 和 ESB 并不是本文的重点，感兴趣的朋友可以从网络上获取更多资料。(可以从上图中看到 ESB 在整个 SOA 架构中所扮演的角色)

**面向对象和面向服务的对比**

面向对象（OO）和面向服务（SO）在基础理念上有大量共通之处，比如都尽可能追求抽象、封装和低耦合。
但SO相对于 OO，又有非常不同的典型应用场景，比如：

● 多数 OO 接口（interface）都只被有限的人使用（比如团队和部门内），而 SO 接口（或者叫契约）一般来说都不应该对使用者的范围作出太多的限定和假设（可以是不同部门，不同企业，不同国家）。还记得贝佐斯原则吗？“团队必须做好规划与设计，以便未来把接口开放给全世界的程序员，没有任何例外”。

● 多数 OO 接口都只在进程内被访问，而SO接口通常都是被远程调用。

● 简单讲，就是 SO 接口使用范围比一般 OO 接口可能广泛得多。我们用网站打个比方：一个大型网站的 web 界面就是它整个系统入口点和边界，可能要面对全世界的访问者（所以经常会做国际化之类的工作），而系统内部传统的 OO 接口和程序则被隐藏在 web 界面之后，只被内部较小范围使用。而理想的 SO 接口和 web 界面一样，也是变成系统入口和边界，可能要对全世界开发者开放，因此 SO 在设计开发之中与 OO 相比其实会有很多不同。

#### 微服务架构

微服务架构(MicroService)是一种服务化架构风格，通过将功能分散到各个离散的服务中以实现对解决方案的解耦。微服务架构强调的第一个重点就是业务系统需要彻底的组件化和服务化（这也是我们为什么要先介绍组件化和服务化的原因）。微服务的诞生并非偶然。它是互联网高速发展，敏捷、精益、持续交付方法论的深入人心，虚拟化技术与 DevOps 文化的快速发展以及传统单块架构无法适应快速变化等多重因素的推动下所诞生的产物。

微服务的流行，Martin 功不可没，先看看他是如何定义微服务的：

> The microservice architectural style is an approach to developing a single application as a suite of small services, each running in its own process and communicating with lightweight mechanisms, often an HTTP resource API. These services are built around business capabilities and independently deployable by fully automated deployment machinery. There is a bare minimum of centralized management of these services , which may be written in different programming languages and use different data storage technologies.

总结起来大概以下四点：

- 一系列的独立的服务共同组成系统
- 单独部署，跑在自己的进程里
- 每个服务为独立的业务开发
- 分布式的管理

Martin自己也说了，每个人对微服务都可以有自己的理解，不过大概的标准还是有一些的。

- 分布式服务组成的系统
- 按照业务而不是技术来划分组织
- 做有生命的产品而不是项目
- Smart endpoints and dumb pipes（我的理解是强服务个体和弱通信）
- 自动化运维（DevOps）
- 容错
- 快速演化



#### 什么是康威定律？

康威定律有各种各样的解读，我觉得比较重要的就是这句话：

> Organizations which design systems are constrained to produce designs which are copies of the communication structures of these organizations. - Melvin Conway(1967)

中文直译大概的意思就是：设计系统的组织，其产生的设计等同于组织之内、组织之间的沟通结构。

简单点说其实就是企业的组织结构决定了业务架构、系统架构。而系统架构的不合理，往往是因为组织架构不合理导致的。

**所以很多人说，康威定律如何在半个世纪前就奠定了微服务架构的理论基础**
（1）人与人的沟通是非常复杂的，一个人的沟通精力是有限的，所以当问题太复杂需要很多人解决的时候，我们需要做拆分组织来达成对沟通效率的管理
（2）组织内人与人的沟通方式决定了他们参与的系统设计，管理者可以通过不同的拆分方式带来不同的团队间沟通方式，从而影响系统设计
（3）如果子系统是内聚的，和外部的沟通边界是明确的，能降低沟通成本，对应的设计也会更加高效。
（4）复杂得系统需要通过容错弹性的方式持续优化，不要指望一个大而全的设计或架构，好的架构和设计都是慢慢迭代出来的

**康威定律的实践建议**
（1） 我们要想尽办法来提升沟通效率，比如使用各种工具。能 2 个人讲清楚的事情，就不要拉更多人，每个人每个系统都有明确的分工，出了问题知道马上找谁，避免踢皮球的问题。
（2） 通过 MVP（Minimum Viable Product即最小化可行产品） 的方式来设计系统，通过不断的迭代来验证优化，系统应该是弹性设计的。
（3） 你想要什么样的系统设计，就架构什么样的团队，能扁平化就扁平化。最好按业务来划分团队，这样能让团队自然的自治内聚，明确的业务边界会减少和外部的沟通成本，每个小团队都对自己的模块的整个生命周期负责，没有边界不清，没有无效的扯皮，inter-operate, not integrate。
（4） 做小而美的团队，人多会带来沟通的成本，让效率下降。亚马逊的 Bezos 有个逗趣的比喻，如果 2 个披萨不够一个团队吃的，那么这个团队就太大了。事实上一般一个互联网公司小产品的团队差不多就是 7，8 人左右（包含前后端测试交互用研等，可能身兼数职）。



#### 如何进行微服务的拆分？

微服务的拆分是一个复杂的过程，要考虑的因素有很多，其中必须要考虑的有业务领域、团队组织结构、技术架构、部署架构等多个方面。

首先最容易想到的就是按照业务功能进行拆分了。将具有不同功能的模块单独拆分出来作为一个微服务。比如用户服务、订单服务、物流服务等，每一个服务作为微服务部署，单独对外提供自己的能力。

第二点，不可忽视的就是微服务和组织架构之间的关系，按照康威定律来说，应用架构和组织架构应该是一一对应的。所以有的时候微服务的拆分也需要按照组织架构进行拆分，这样更加容易的进行微服务的开发与维护，能够做到最小成本沟通和最快速度的迭代。比如有些公司做了中台，那么就可能有单独的一些中台相关的微服务，如交易服务、店铺服务等。

第三，按照应用类型进行拆分。有一些应用主要处理在线业务，而有些系统专门处理离线业务，那么就可以把他们拆分开，让在线业务和离线业务分离，避免互相影响。

还有，按照技术架构拆分。比如不同的技术栈、使用不同的中间件体系，不同的开发语言等等。这些拆分开有利于独立维护。

除了以上说的这些，还有很多其他的方面，比如按照部署架构等。



#### 微服务架构的服务治理有哪些实现方案？

服务治理是微服务架构中比较重要的一个课题，很多人不知道什么叫做服务治理，但是你一定听说过服务注册与发现、负载均衡、容错与熔断、限流与流量控制、服务监控与追踪等，这些都是服务治理的一部分。

所以，要做不同的事情， 有很多不同的方案，我们挑其中的重点介绍一下都有哪些方案，但是每个方案并不会深入的拆解，大家可以在本文库中其他章节寻找，几乎都有涉及。

**服务注册与发现**是微服务架构中必不可少的一个环节。微服务可以向注册中心注册服务的信息（如地址、端口等），其他微服务可以通过服务发现机制动态地获取可以进行调用的服务信息，从而实现服务之间的通信。

常见的实现方案有：

- ZooKeeper
- Consul
- Eureka

**负载均衡**是指将请求分配到多个服务实例中，以达到分摊负载的目的，常见的实现方案有：

- Ribbon：Ribbon 是 Netflix 开源的一个负载均衡框架，可以与 Eureka 配合使用。
- Nginx：Nginx 是一个高性能的 Web 服务器，也可以用作反向代理和负载均衡器，可以实现对多个服务实例的负载均衡。

**熔断机制**，当某个微服务发生故障或不可用时，可以快速断开该服务的调用，防止故障扩散，并提供备用响应或执行其他补救措施。这就是熔断机制。常见的实现方案有：

- Hystrix：Hystrix 是 Netflix 开源的一个容错框架，可以实现服务的熔断、降级和容错等功能。
- Sentinel：Sentinel 是阿里开源的一个流量控制和容错框架，可以实现服务的熔断、降级、限流和系统保护等功能。

**限流机制**，限制服务的访问量，通过限制每个微服务的请求频率或并发数，防止服务过载和雪崩效应的发生。以保证服务的可用性和稳定性，常见的实现方案有：

- Rate Limiter：Rate Limiter 是 Google 开源的一个限流框架，可以实现对访问频率的限制。
- Istio：Istio是由 Google、IBM 和 Lyft 等公司共同推出的一个服务网格框架，可以实现对服务流量的控制和管理。
- Sentinel：Sentinel 也支持限流的功能。

**降级机制**，在资源紧张或故障情况下，可以通过降级机制优先处理重要或核心功能，暂时关闭非关键功能，保证核心功能的正常运行。常见的实现方案有：

- Hystrix：Hystrix 是 Netflix 开源的一个容错框架，可以实现服务的熔断、降级和容错等功能。
- Sentinel：Sentinel 也支持降级的功能。

**分布式链路追踪**，通过对微服务调用链路进行追踪和监控，可以帮助定位问题、优化性能，并提供可视化的调用链路图。常见的实现方案有：

- skywalking：Skywalking 是分布式系统的应用程序性能监视工具，专为微服务，云原生架构和基于容器（Docker，K8S,Mesos）架构而设计，它是一款优秀的 APM 工具，包括了分布式追踪，性能指标分析和服务依赖分析等。
- zipkin：Zipkin 是 Twitter 的一个开源项目，基于 Google Dapper 实现。 可以使用它来收集各个服务器上请求链路的跟踪数据，并通过它提供的 REST API 接口来辅助我们查询跟踪数据以实现对分布式系统的监控程序，从而及时地发现系统中出现的延迟升高问题并找出系统性能瓶颈的根源。

**服务监控**是指对服务进行实时监控和追踪，以及对服务性能进行评估和优化，常见的实现方案有：

- Prometheus：Prometheus 是由 SoundCloud 开源的一个监控系统，可以实现对服务的实时监控和度量。



#### 什么是 DevOps？

现在很多公司和团队都在提 DevOps，这其实不是个技术，其实是一种开发流程，或者说一种开发文化。它强调软件开发和IT运维的紧密结合，以实现更快速、更频繁、更可靠的软件交付。DevOps 的核心目标是提高软件交付的速度和质量，缩短软件上线的周期，同时提高应用程序的可靠性和可维护性。

DevOps 的出现是为了解决传统软件开发和运维模式中存在的问题，例如开发和运维之间的沟通不畅、软件交付周期过长、人工操作错误率高、应用程序可靠性低等。通过采用 DevOps 理念和工具，企业可以更快速、更高效地推出新的软件功能，降低软件交付成本，提高客户满意度。

和传统的开发方式上比较的区别是：

以前的开发模式中，开发和运维团队是完全独立开的，开发负责应用开发，运维团队负责打包和发布。出了问题各自看各自的问题。

但是在 DevOps 的实践中，开发团队和运维团队不再是独立的个体，而是合作伙伴，共同负责整个软件的全生命周期，甚至有些公司直接不要运维团队了，由开发自己做运维。

之所以可以这么做，是因为有很多持续集成、持续交付和持续部署的自动化工具的出现。



#### 微服务中的 CI/CD 了解吗？

CI 是 Continuous Integration，翻译过来是持续集成，CD 可以是 Continuous Delivery 也可以是 Continuous Deployment，翻译过来分别是持续交付和持续部署。

持续集成

持续集成是一种软件开发实践，要求开发者经常集成其变更，方式是将变更合并到主干（trunk）。

持续集成通常通过自动化的构建判定多个变更是否已就绪来实现，也就是说，持续集成可以快速地决定一组变更是否可部署，也可以检测到应用内容的遗漏，包括代码错误、缺失的文件，以及单元测试中潜在的错误。

**持续交付**

持续交付（CD）是一种软件开发实践，旨在早期、快速、可靠地发布高质量软件，以满足业务需求。

持续交付构建、测试和部署系统，这些步骤综合在一起以实现及时部署，包括自动化测试、可跟踪性和可扩展性，以及触发维护活动时的预警。

持续交付在持续集成的基础上，将集成后的代码部署到更贴近真实运行环境的「类生产环境」（production-like environments）中。比如，我们完成单元测试后，可以把代码部署到连接数据库的 Staging 环境中更多的测试。如果代码没有问题，可以继续手动部署到生产环境中。

**持续部署**

持续部署（CD）指的是在持续集成完成后，直接向生产环境部署应用，或者是定期将新功能部署到生产环境的过程。

持续部署通常需要由一组自动化步骤来实现，比如云计算，必要的负载均衡和其它依赖准备工作。

持续部署则是在持续交付的基础上，把部署到生产环境的过程自动化。



#### 听说过 ServiceMesh 吗？是什么？

Service Mesh 是一个比较新的概念，用于解决微服务架构中的一些问题，如服务发现、服务间通信、负载均衡、安全、监控等。

它是一种新型的架构模式，主要思想是将服务之间的通信从服务代码中抽象出来，并在整个应用中提供一种统一的方式进行管理和控制。

> Service Mesh 代理通常是以 sidecar 的方式部署在每个服务实例旁边，它们可以拦截和处理来自服务实例的所有网络流量，并提供各种功能，例如负载均衡、故障转移、熔断、限流、安全、监控等。Service Mesh 代理可以提供更细粒度的控制和管理，例如在请求级别进行路由和重试，并且可以实时监控和调整服务的行为。

目前比较流行的 Service Mesh 产品包括 Istio、Linkerd、Envoy 等。

Service Mesh 一般在异构系统中用的比较多，比如一家公司的技术栈比较杂，既有Java、又有C++，还有Python，PHP等 ，通过Service Mesh 可以很好的用同一套架构体系将异构语言的程序员整合到一起。

除了前面说的这些，ServiceMesh 在实际应用中，还会用来实现以下以下一些功能：

1. rpc 转 http，http 转 rpc，用于调用者不支持 rpc 的情况
2. 真实流量压测，将多机的流量转发到一台机器上
3. 精准的流量分析，如 vip 日志，针对某个用户维度的全链路流量跟踪
4. 服务健康状态巡检，分析服务的异常，qps，使用率等信息生成报告，并对比历史数据给出异常告警
5. 提供数据通路，服务自身可以通过这个通路上报各种非业务性质的内部状态
6. 流量拷贝和镜像，把流量拷贝到测试环境，再通过 data mesh 提供 cow 与线上数据环境打通，同时不影响线上业务数据。这样排查问题非常方便
7. 加速服务通信性能，mesh agnet 位于服务机器内，通过lo与服务通信代理流量作为统一流量入口。lo不会过内核协议栈，大幅度降低 cpu 压力和耗时。而 mesh agent 自身收发网络流量也可以使用 ebpf 或者 dpdk 这样 kernel-bypass 技术绕过协议栈协议解析，降低 cpu 压力和耗时。整体通信成本大幅度降低，使用 mesh 前耗时 10-20ms 可降低到几 ms。



#### 灰度发布、蓝绿部署、金丝雀部署都是什么？

蓝绿部署、金丝雀发布（灰度发布）这些都是软件部署和发布中常用的一些策略和技术，用于实现在生产环境中逐步更新和验证新版本的方式。它们的主要目标是降低部署风险、确保服务稳定性，并实现快速、高效的软件发布。

**蓝绿部署**是一种在部署新版本时，准备两套完全相同的生产环境，称为蓝环境（Blue Environment）和绿环境（Green Environment）。初始状态下，用户的请求都会被路由到蓝环境，而绿环境处于闲置状态。

当新版本部署完成并测试通过后，将流量切换到绿环境，此时绿环境变为主要的生产环境，而蓝环境则成为备份环境。

当然，在这个切流过程也不是一下100%都要切过来的，也可以先切流一部分，观察一段时间，然后再逐步扩大切流比例，最终完成整体切流。

蓝绿部署的优点是可以实现快速回滚，只需要将流量切回到蓝环境即可。但是他的缺点也比较明显，蓝绿部署有一套闲置环境，这就意味着有一半的机器是不会对外提供服务的，那么就会导致很大的资源浪费。

**金丝雀发布**，其实就是灰度发布，之所以叫金丝雀发布，是因为金丝雀对矿场中的毒气比较敏感，所以在矿场开工前工人们会放一只金丝雀进去，以验证矿场是否存在毒气。

与蓝绿部署不同的是，它不需要有一组闲置的服务器，他又叫灰度发布。

在这种方式中，会在整个服务器集群中，挑选一部分机器进行灰度发布，发布会直接对外提供服务，通过给这些已发布的机器引流，来验证服务是否正常。

通过灰度发布，可以在生产环境中测试新版本的稳定性和性能，如果发现问题，可以及时回滚或修复。逐渐增加新版本的流量也可以降低风险，确保系统的稳定性。

一般来说，灰度发布要比蓝绿发布好一些，毕竟他没那么浪费资源，唯一的问题就是回滚不太容易做，需要把已发布应用退回到上一个版本中。

> 如何快速回滚 ?
>
> 有个好的办法，那就是记录基线。应用在发布前，把应用相关的内容，如环境、容器、war 包等全部都记录下来，在需要回滚时，直接基于这个基线进行快速部署即可。



#### 什么是微服务的循环依赖？

微服务之间的循环依赖是指在微服务架构中，两个或多个服务相互依赖对方的情况。这里的依赖其实就是互相调用。两个微服务互相调用，A调用B，B又反向调用A，或者A调用B，B调用C，C调用A，这都是循环依赖。

举个例子，假设我们有两个微服务：订单服务（Order Service）和库存服务（Inventory Service）。

**1、订单服务（Order Service）：**

- 当用户下单时，订单服务需要调用库存服务来检查所需商品的库存。
- 如果库存充足，订单服务会继续处理订单。

**2、库存服务（Inventory Service）：**

- 当库存服务更新库存时，它需要通知订单服务更新订单状态。
- 为此，库存服务会调用订单服务的一个接口。

**这里的循环依赖出现在：**

- 订单服务依赖库存服务来验证库存。
- 库存服务依赖订单服务来更新订单状态。

**我们在做设计的时候应该尽量的避免循环依赖，因为循环依赖会导致以下这些问题：**

**1、流量放大：**因为系统之间存在循环依赖，那么就会导致本来下单系统可能只有 100 QPS，但是因为存在循环依赖，就会导致这个 QPS 被放大，因为 100 个请求调用到订单服务，订单服务就有 100 个请求调到库存服务，而库存服务又有 100 个请求再调到订单服务。就导致订单服务有 200 的 QPS 了。无形中被放大了流量。

**2、性能问题：**因为存在循环依赖，那么服务之间需要等待彼此的响应，就会无形中拖长请求的 RT，让接口性能变的更慢。

**3、互相影响：**如果一个服务出现问题，这个问题可能会通过循环依赖影响到另一个服务。而一个服务中的错误可能通过依赖链传播到其他服务，增加了系统出现级联故障的风险。

**4、发布困难：**每当一个服务需要更新时，我们需要同时考虑他依赖了谁以及谁依赖了他。一般是被依赖的应用先发布。但是因为系统间存在循环依赖，那么在上一个新的功能的时候需要发布时，就会带来很大的问题，那就是谁先发的问题，而谁先发都会有问题。

主要就是以上这几个问题，所以我们平时需要尽量的避免循环依赖。



#### 循环依赖如何解决？

首先，遇到循环依赖的问题，第一件事就是考虑设计的不合理性，一般来说系统会有自己的明确的职责，并且一张架构图中，一个系统一定是有属于他自己的位置的，一个系统又在上游，又在下游，那一定是设计的不合理，所以需要考虑做**重新设计**。

其次，像前面我们提到的例子，库存需要通知订单更新状态，这个过程我们可以把服务调用改成**消息通信**，通过异步消息来解耦调两个系统之间的相互依赖。这样就可以避免互相影响。

另外，比较常用的一种方式，那就是引入一个**共享库**，当出现循环依赖时候，可以考虑将共享部分抽取出来作为一个共享库，然后由各个相关服务共同引用这个库。通过在循环依赖的两个微服务中引用共享库，而不是直接调用对方的接口来操作数据。

上面的共享库，也可以做成一个**共享服务（或者叫中介服务）**，你俩不是互相依赖么，那么干脆我单独搞一个服务出来，你们都直接依赖他而不是做互相依赖。比如我们实际业务中就有一个台账系统，我们会把各个业务流水都写到台账中，所以当我们上游系统之间需要查询数据的时候，就可以直接去台账查，而不需要依赖其他的系统。而台账作为最下游系统，他也不会调用任何其他服务，他最多会提供消息给别的系统。



#### 如何识别循环依赖？

要解决循环依赖，首先需要识别出来。那么具体如何识别呢？

首先，一个一劳永逸的方式，就是有一个明确地架构图，架构图中明确的标注出来各个系统处于什么位置，上游系统都有谁，下游系统都有谁，依赖只能是从上到下的，而不能是从下到上的。有了这样一张图，大家就都知道，我自己的系统处于什么位置，我可以依赖谁，谁可以依赖我了。

其实就是可以通过**链路追踪**来看是否存在循环依赖，当一个调用的 trace 中，一个应用被调用多次，那么可能就会存在循环依赖的问题。

还有就是通过各种**评审**来发现了，比如我们前面提到的，循环依赖会导致发布过程存在谁先发的问题，这个问题在发布评审时是一定可以暴露出来的。

所以，在设计评审，发布评审，TC评审，以及代码评审的时候，需要关注一下是否存在着循环依赖的问题。



#### 限流、降级、熔断有什么区别？

限流、降级和熔断是三种常用的系统稳定性策略，它们在高并发和高负载的场景下尤为重要。通常我们说为了保证系统的可用性，限流、降级、熔断一把梭，但是其实他们是三个不太相同的概念，作用也不太一样。

**限流**

限流的目的是控制系统的并发流量，通过限制请求流量的手段防止过度的流量导致系统崩溃。一般用于应对突发流量高峰。

一般是被调用方对调用方进行限流。举个例子，我提供了一个查询用户信息的服务，给集团内外的很多个调用方使用，但是我为了保证我的可用性，我会对每个调用方做限流，防止某个调用方不守规矩，把我的服务打挂了。

> 当然，也有在服务端给客户端直接做限流的，一般用于外部服务能力不太行的时候，比如电商网站大促的时候，可能会依赖很多银行的服务，但是银行服务本身可能没那么高的并发， 所以可能在电商网站上自己控制一下 QPS，来起到限流的目的，避免下游系统被打挂。

**降级**

降级是当系统负载过高时，主动关闭一些非核心功能，以确保核心功能的正常运行。一般用于在系统资源有限或响应时间过长时，通过降低服务质量保障核心服务。

举个例子，双十一大促期间，淘宝上面会把退款功能关闭，这就是一种降级手段，通过把一些非核心功能降级掉来保证核心功能可用。或者在某次腾讯视频挂了的时候，用户名称默认显示腾讯用户，这也是一种降级方式，用兜底名称做展示.

降级可以做在客户端，也可以做在服务端，比如关闭部分非核心功能的话，可以直接把入口关掉，及服务端直接下掉入口。也可以客户端直接返回兜底逻辑，不做业务逻辑处理起到降级的目的。

**熔断**

熔断是为了防止系统因某个服务的故障而整体崩溃，类似于电路的熔断器。在检测到下游服务异常时，自动停止向该服务发送请求，并在一定时间后尝试恢复。

熔断一般发生在调用方，举个例子，当电商平台上用户支付时，收银台发现某个支付渠道，如微信支付失败率突增，超时严重，那么就可以临时把这个支付方式熔断掉。

|        | 限流                                                         | 降级                                                         | 熔断                                                         |
| ------ | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 目的   | 控制系统的流量，防止过度的流量导致系统崩溃。                 | 主动关闭一些非核心功能，以确保核心功能的正常运行。           | 防止系统因某个服务的故障而整体崩溃，类似于电路的熔断器。     |
| 手段   | 各种限流算法：滑动窗口、漏桶、令牌桶                         | 开关；通过开关控制某些功能直接被降级。                       | 熔断器                                                       |
| 工具   | Sentinel                                                     | Sentinel                                                     | Sentinel                                                     |
| 示例   | 我提供了一个查询用户信息的服务，给集团内外的很多个调用方使用，但是我为了保证我的可用性，我会对每个调用方做限流，防止某个调用方不守规矩，把我的服务打挂了。 | 双十一大促期间，淘宝上面会把退款功能关闭<br/><br/>某次腾讯视频挂了的时候，用户名称默认显示腾讯用户，这也是一种降级方式，用兜底名称做展示 | 当电商平台上用户支付时，收银台发现某个支付渠道，如微信支付失败率突增，超时严重，那么就可以临时把这个支付方式熔断掉。 |
| 发起方 | 被调用方（客户端）/调用方（服务端）                          | 被调用方（客户端）/调用方（服务端）                          | 调用方（服务端）                                             |



#### 注册中心如何选型？

配置中心有很多成熟的工具，如 Zookeeper、Nacos、Eureka、Consul 等。

Zookeeper 是最早流行的开源分布式协调服务框架之一，同时也提供了分布式配置中心的功能。Zookeeper 以高可用、一致性和可靠性著称，但是需要用户自己来开发实现分布式配置的功能。

Nacos 是阿里巴巴开源的服务注册中心和配置中心。与 Zookeeper 不同的是，Nacos 自带了配置中心功能，并提供了更多的可视化配置管理工具。Nacos 的目标是成为一个更全面的云原生服务发现、配置和管理平台。

Eureka 是 Netflix 开源的服务注册中心，被广泛应用在 Spring Cloud 微服务架构中。它提供了易于使用的 REST API 和 Web 界面，并支持基于 Region 和 Zone 的服务分组和负载均衡。

Consul 是 HashiCorp 开源的服务注册中心和配置中心，提供了服务发现、健康检查、KV 存储和多数据中心功能。Consul 提供了更丰富的健康检查和路由功能，同时也提供了丰富的 API 和 Web UI。

|                  | Nacos                       | Eureka      | Consul            | Zookeeper  |
| ---------------- | --------------------------- | ----------- | ----------------- | ---------- |
| CAP              | CP + AP                     | AP          | CP                | CP         |
| 健康检查         | TCP/HTTP/MYSQL/Client Beat  | Client Beat | TCP/HTTP/gRPC/Cmd | Keep Alive |
| 负载均衡         | 权重/<br/>metadata/Selector | Ribbon      | Fabio             | ——         |
| 一致性算法       | Raft/Distro                 | Gossip      | Raft              | ZAB        |
| 雪崩保护         | 有                          | 有          | 无                | 无         |
| 访问协议         | HTTP/DNS                    | HTTP        | HTTP/DNS          | TCP        |
| 跨注册中心同步   | 支持                        | 不支持      | 支持              | 不支持     |
| Spring Cloud集成 | 支持                        | 支持        | 支持              | 支持       |
| Dubbo 集成       | 支持                        | 不支持      | 支持              | 支持       |
| K8s 集成         | 支持                        | 不支持      | 支持              | 支持       |

选择服务注册中心和配置中心需要考虑应用场景、功能需求、易用性和维护成本等因素，有以下几个原则供参考：

如果对一致性要求高，建议考虑支持 CP 模型的 Consul、Nacos 以及 ZK

如果应用已经在使用 Spring Cloud 框架，则建议使用 Eureka；

如果应用在用 `Dubbo/Spring Cloud Alibaba`，或者需要一套更全面的云原生服务治理平台，则建议使用 Nacos；

如果需要更强大的健康检查和路由功能，则建议使用 Consul。虽然 Nacos 和 Eureka 都支持服务健康检查和路由功能，但是 Consul 在这方面的功能更为强大，比如 Consul 支持多种健康检查方式（TCP、HTTP、gRPC等）、支持自定义健康检查脚本，可以更精细地控制服务的健康状况。

当然，Zookeeper 也是一款成熟的分布式协调服务框架，如果已经熟悉使用 Zookeeper，也可以考虑使用 Zookeeper 作为服务注册中心和配置中心。



#### 什么是 Nacos，主要用来作什么？

Nacos是一个基于云原生架构的动态服务发现、配置管理和服务治理平台。支持多种编程语言和多种部署方式，并且与 Spring Cloud 等主流的微服务框架深度集成。

**配置管理：**可以将应用程序的配置信息存储在 Nacos 的配置中心，通过 Nacos 实现动态配置管理和灰度发布，从而实现应用程序的动态调整和部署。

**服务发现及注册：**可以将服务注册到 Nacos 注册中心，并通过 Nacos 实现服务的自动发现和负载均衡，从而实现服务的高可用和弹性伸缩。

**服务治理：**可以通过 Nacos 实现服务的健康检查、故障转移、服务限流、熔断降级等治理能力，从而提高服务的可靠性和稳定性。

**事件监听和推送：**可以通过 Nacos 实现配置变更、服务注册和注销等事件的监听和推送，从而实现应用程序的自动化部署和管理。

> 哪些服务用到了 Nacos？
>
> 1、Spring Cloud Alibaba：Nacos 是 Spring Cloud Alibaba 的核心组件之一，可以和 Spring Cloud 集成，实现服务发现、负载均衡、配置管理等功能。
>
> 2、Dubbo：Nacos 是 Dubbo 2.7.x 版本的服务注册中心和配置中心，可以通过 Nacos 实现服务的动态发现和配置管理。
>
> 3、Kubernetes：Nacos可以作为 Kubernetes 的服务注册中心和配置管理平台，可以将 Kubernetes 中的服务注册到 Nacos 中，并通过 Nacos 进行服务发现和负载均衡。
>
> 4、Service Mesh：Nacos 可以作为 Service Mesh 的控制面板，实现服务的配置管理、流量控制和熔断降级等功能。



#### Nacos 是 AP 的还是 CP 的？

Nacos 支持 AP 和 CP 两种模式，可以根据具体的使用场景进行选择。默认情况下是 AP 模式，可以通过修改 nacos 的配置文件来切换 AP/CP。

在 AP 模式下，Nacos 保证高可用性和可伸缩性，但不保证强一致性。在 CP 模式下，Nacos 保证强一致性，但可能会降低可用性和可伸缩性。

在实际应用中，具体应该采用哪种模式，需要根据业务的特点和需求来判断。

**如果在分布式系统中，某些数据的一致性对业务有非常高的要求，例如金融、支付等场景，那么可以选择使用 CP 模式**。在 CP 模式下，当发生网络分区或故障时，为了保证数据一致性，Nacos 会对服务进行自动隔离和恢复。但是，这会导致部分服务不可用，因此可用性会受到影响。

**如果对于某些服务来说，可用性比一致性更加重要，例如网站、在线游戏等场景，那么可以选择使用 AP 模式**。在 AP 模式下， Nacos 会优先保证服务的可用性，如果发生了网络分区或故障，Nacos 会在保证一定的可用性的前提下，尽可能保持数据一致性。这样虽然可能会导致数据不一致的情况，但是可以保证服务的可用性，从而减少业务的影响。



#### Nacos 如何实现的配置变化客户端可以感知到？

