# 面试题-架构设计

#### 如何设计一个高性能的分布式系统？

设计高性能的分布式系统需要考虑多个因素，包括架构设计、负载均衡、数据一致性、容错处理、消息队列、缓存、性能监控和安全性等。下面是一些可以帮助设计高性能分布式系统的方法：

1. 架构设计：选择合适的分布式系统架构，例如微服务架构、SOA架构等，可以有效地提高系统性能。
2. 负载均衡：使用负载均衡技术可以将请求分布到多个节点上，提高系统的性能和可用性。可以使用硬件负载均衡器或软件负载均衡器来实现。
3. 数据一致性：保证数据一致性是设计分布式系统的一个重要方面，可以使用一致性哈希、副本复制、分片等技术来保证数据一致性。
4. 容错处理：设计分布式系统时必须考虑容错处理，以防止单点故障。可以使用备份、自动故障转移、容器化等技术来实现容错处理。
5. 消息队列：使用消息队列可以解耦系统组件，提高系统的可伸缩性和性能。
6. 缓存：使用缓存技术可以减轻数据库的负载，提高系统性能。
7. 性能监控：使用性能监控工具可以监测系统的性能瓶颈，提高系统的性能和可用性。
8. 安全性：分布式系统的安全性是至关重要的，可以使用身份验证、访问控制等技术来保证系统的安全性。

#### 什么是QPS，什么是RT？

QPS，指的是系统每秒能处理的请求数(Query Per Second) ，在Web应用中我们更关注的是Web应用每秒能处理的request数量。这个是衡量系统性能的重要指标。

RT，指的是响应时间(Response Time)，是指从客户端发一个请求开始计时，到客户端接收到从服务器端返回的响应结果结束所经历的时间。

#### 服务端接口性能优化有哪些方案？

设计调优、代码调优、JVM调优、数据库调优、操作系统调优。

- 使用单例
- 批量操作
- 使用 Future 模式
- 使用线程池
- 使用 NIO
- 锁优化
- 压缩传输
- 缓存结果
- SQL 优化

#### 什么是布隆过滤器，实现原理是什么？

布隆过滤器是一种数据结构，用于快速检索一个元素是否可能存在于一个集合(bit 数组)中。

它的基本原理是利用多个哈希函数，将一个元素映射成多个位，然后将这些位设置为 1。当查询一个元素时，如果这些位都被设置为 1，则认为元素可能存在于集合中，否则肯定不存在。

所以，布隆过滤器可以准确的判断一个元素是否一定不存在，但是因为哈希冲突的存在，所以他没办法判断一个元素一定存在。只能判断可能存在。

下面是布隆过滤器的工作过程：

**1、初始化布隆过滤器**
在初始化布隆过滤器时，需要指定集合的大小和误判率。布隆过滤器内部包含一个bit数组和多个哈希函数，每个哈希函数都会生成一个索引值。

**2、添加元素到布隆过滤器**
要将一个元素添加到布隆过滤器中，首先需要将该元素通过多个哈希函数生成多个索引值，然后将这些索引值对应的位设置为 1。如果这些索引值已经被设置为 1，则不需要再次设置。

**3、查询元素是否存在于布隆过滤器中**
要查询一个元素是否存在于布隆过滤器中，需要将该元素通过多个哈希函数生成多个索引值，并判断这些索引值对应的位是否都被设置为 1。如果这些位都被设置为 1，则认为元素可能存在于集合中，否则肯定不存在。

布隆过滤器的主要优点是可以快速判断一个元素是否属于某个集合，并且可以在空间和时间上实现较高的效率。但是，它也存在一些缺点，例如：

1. 布隆过滤器在判断元素是否存在时，有一定的误判率。
2. 布隆过滤器删除元素比较困难，因为删除一个元素需要将其对应的多个位设置为 0，但这些位可能被其他元素共享。

#### 什么是读写分离？如何实现？

在分布式系统设计中，读写分离是一种常见的架构模式，可以提升系统的处理能力、扩展性和可用性。简单来说就是分开处理读和写操作。

- 读操作：通常指的是从数据库中检索数据的操作，比如 SQL 查询。
- 写操作：包括创建、更新或删除数据库中的数据，比如 SQL 的 INSERT、UPDATE、DELETE 语句。

读写分离的好处：

1. 提高性能：一般来说，大型分布式应用中都是读多写少的。将读写操作分离可以显著提高数据库系统的整体性能。
2. 提高可扩展性：读写分离允许系统按需增加从数据库实例，以应对读请求量的增长，从而提高系统的可扩展性。
3. 增加可用性和容错性：在主-从复制架构中，如果主数据库出现故障，可以从从数据库中选举或提升一个为新的主数据库，从而减少系统的停机时间。
4. 负载均衡：通过在多个从数据库之间分散读请求，可以实现负载均衡，避免单个数据库的过载，从而提高系统的响应速度和稳定性。

我们都知道 MySQL 提供了主从复制的能力，所以我们就可以基于 MySQL 自带的主从复制的能力来实现读写分离。

> 在这种模式下，写操作只在主数据库（Master）上执行，而读操作则可以在从数据库（Slave）上执行。主库和从库通过主从复制来保持数据的同步。

**如何做读写的分流？**

如何实现让写流量请求到主库，读流量请求到从库呢，这就涉及到具体的读写分流了。

一般来说，首先我们需要把接口从定义上或者从职责上划分清楚，读接口和写接口。如 UserReadService 就是专门负责提供读服务的，UserWriteService 就是专门负责写服务的。

接下来，ReadService 在操作的时候，只需要和从库进行交互，而 WriteServie 在操作的时候只需要和主库进行操作就行了。具体分流方式有以下集中：

- 代码分流

> 最简单直观的方式，就是我们自己编码实现，我们可以在 DAO 层定义多个数据源，然后在实际进行读或者写操作的时候，选择使用不同的数据源即可。
>
> 如以下方式定义两个不同的 DataSource：

```java
@Configuration
public class DataSourceConfig {

    @Bean
    @Primary
    public DataSource primaryDataSource() {
        // 配置主数据源
        return DataSourceBuilder.create().url("jdbc:mysql://master_db:3306/mydb").username("user").password("pass").build();
    }

    @Bean
    public DataSource replicaDataSource() {
        // 配置从数据源
        return DataSourceBuilder.create().url("jdbc:mysql://replica_db:3306/mydb").username("user").password("pass").build();
    }
}
```

在定义一个动态数据源：

```java
public class DynamicDataSource extends AbstractRoutingDataSource {
    @Override
    protected Object determineCurrentLookupKey() {
        // 你可以根据实际情况来决定使用哪个数据源
        return DbContextHolder.getDbType();
    }
}
```

在 Spring 配置中设置 DynamicDataSource，并将之前定义的主从数据源作为目标数据源。

```java
@Configuration
public class RoutingConfig {

    @Autowired
    @Qualifier("primaryDataSource")
    private DataSource primaryDataSource;

    @Autowired
    @Qualifier("replicaDataSource")
    private DataSource replicaDataSource;

    @Bean
    public DataSource dataSource() {
        DynamicDataSource dynamicDataSource = new DynamicDataSource();
        Map<Object, Object> targetDataSources = new HashMap<>();
        targetDataSources.put(DbType.MASTER, primaryDataSource);
        targetDataSources.put(DbType.SLAVE, replicaDataSource);
        dynamicDataSource.setTargetDataSources(targetDataSources);
        dynamicDataSource.setDefaultTargetDataSource(primaryDataSource); // 默认使用主数据源
        return dynamicDataSource;
    }
}
```

通过 AOP 在业务层或 DAO 层方法调用前动态切换数据源。可以基于注解或方法名称约定来拦截方法调用。针对 find 方法使用从库，针对 insert 方法使用主库。

```java
@Aspect
@Component
public class DataSourceAspect {

    @Before("execution(* com.example.repository..*.find*(..)) || execution(* com.example.repository..*.get*(..))")
    public void setReadDataSourceType() {
        DbContextHolder.setDbType(DbType.SLAVE);
    }

    @Before("execution(* com.example.repository..*.insert*(..)) || execution(* com.example.repository..*.update*(..))")
    public void setWriteDataSourceType() {
        DbContextHolder.setDbType(DbType.MASTER);
    }

    @After("execution(* com.example.repository..*.*(..))")
    public void clearDataSourceType() {
        DbContextHolder.clearDbType();
    }
}


public class DbContextHolder {

    private static final ThreadLocal<DbType> contextHolder = new ThreadLocal<>();

    public static void setDbType(DbType dbType) {
        contextHolder.set(dbType);
    }

    public static DbType getDbType() {
        return contextHolder.get();
    }

    public static void clearDbType() {
        contextHolder.remove();
    }

    public enum DbType {
        MASTER, SLAVE
    }
}
```

这种方案的好处就是实现起来简单，我们可以根据业务做各种定制化，灵活性非常好。

- 借助中间件**（推荐）**

> 对于这种读写分离的场景，有很多中间件就天然支持的。比如Sharding-JDBC 、TDDL等，都是支持读写分离的。
>
> 他们的实现原理主要是根据 SQL 语义的分析，将读操作和写操作分别路由至主库与从库。
>
> 这个方案在可靠性、侵入性、稳定性方面更加友好。

- 代理模式

> 那就是在应用程序和数据库实例之间部署一组数据库代理实例，对应用程序来说，数据库代理把自己伪装成一个单节点的 MySQL 实例，应用程序的所有数据库请求被发送给代理，代理分离读写请求，然后转发给对应的数据库实例。
>
> 这种方案中，比较典型的是 Atlas，这是奇虎 360 研发的数据中间层项目。Atlas 是一个位于应用程序与 MySQL 之间中间件。在后端 DB 看来，Atlas相当于连接它的客户端，在应用层面看来，Atlas 相当于一个 DB 服务器。
>
> 以一主多从为例。Atlas 可以将读请求分发到两个从库节点，写请求分发到主库节点，实现读写分离。

MySQL 8.2 开始的 Router 也能用来做读写分离了。

#### 读写分离遇到主从延迟怎么办？

正常情况下，MySQL 的主从延迟都是非常小的，一般都不超过 1ms。但是在极端情况下也会出现查不到的情况。所以，我们需要想办法解决这个问题。

一般来说，为了减少主从延迟带来的影响，我们在实现读写分离时，可以采用以下几种方案做优化。

**读请求分类**

一般来说，虽然我们做了读写分离，但是也不是无脑分的，我们还会把读请求分成两类，一类是可以接受延迟的读，一类是不能接受延迟的读。

比如历史订单的查询、比如数据报表的生成、比如数据对账的查询、比如非关键业务的查询，比如评论信息等，这些都是可以延迟的读，这些读的话就可以完全从备库走。

而对于那些不能接受延迟的读，那么就需要注意了，就需要考虑进行强制读主库。

这种方案其实是用的比较多的，不要以为他是逃避了问题，有的时候，没必要给自己创造困难硬上！

**强制读主库**

上面我们提到了对于一些不能接受延迟的读请求，需要强制走主库。

还有一些情况，那就是一些核心的业务操作，或者是在一个事务上下文中的读请求，这时候也需要读主库的。

比如说我在创建订单的过程中，我会先插入一个订单，然后再查询订单信息进行后续操作，这个过程中，是要保证数据一定能查到的，这时候就也需要强制走主库。

具体如何实现强制读主库呢，如果是我们前面介绍的通过自己写代码分流的方案的话，就比较容易了，我们可以自己控制读写哪个数据源，那么就自己硬编码就好了。

如果是使用我推荐的中间件的方案的话，比如 ShardingJDBC，他也是支持强制路由的（https://shardingsphere.apache.org/document/legacy/3.x/document/cn/manual/sharding-jdbc/usage/hint/ ），可以通过设置hint的方式让 SQL 只操作主库。

**二次读取**

除了上面我们说的强制读主库的方案，还有一个常见做法叫做二次读取。

啥意思呢，就是我的读取操作，默认读从库，但是如果我从库读取的时候没读到，那我为了避免因为数据延迟导致的，那么就再进行一次从主库读取。

这个实现方式的话也是需要我们定制的开发代码。但是这个方案我不太建议，因为这种一旦出现延迟，也会导致你的主库会有大量的请求过去，造成很大的压力的。

**主备一致**

除了上面说的方案之外，还有一些场景中，是采用了一些特殊的手段，来确保主备一致。

- Sleep方案：就是主库更新之后，读从库之前先sleep 1秒，然后再读从库。
- 判断主备无延迟方案：每次从库执行查询请求前，先判断 seconds_behind_master 是否已经等于 0。如果还不等于 0 ，那就必须等到这个参数变为 0 才能执行查询请求。
- 等主库位点方案：其核心思想是在从库上执行读操作前，确保从库已经同步了特定的主库位点（即主库的数据变更位置）。这样可以保证读操作获取的数据是最新的，避免了因主从复制延迟而导致的数据不一致问题。
- 等 GTID 方案：和位点原理一样，MySQL 5.7.6 版本开始，允许在执行完更新类事务后，把这个事务的 GTID 返回给客户端，在执行读操作前，应用检查从库是否已经应用了该 GTID 标识的事务。这通常涉及查询从库的复制状态，确认已经处理的 GTID 集合包含了特定的 GTID。

> GTID（Global Transaction Identifier）为每个事务提供了一个全局唯一的标识符，使得主从复制过程中的数据变更能够更加精确和容易追踪。

#### 什么是SLA？

