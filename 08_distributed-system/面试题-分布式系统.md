# 面试题-分布式系统

#### 什么是分布式系统？和集群的区别？

分布式是针对集中式来说的，先说集中式，集中式系统就是把一整个系统的所有功能，包括数据库等等全部都部署在一起，通过一个整套系统对外提供服务。但是集中式系统存在系统大而复杂、难于维护、容易发生单点故障、扩展性差等问题。而这些问题在分布式系统中可以很好的解决。

分布式就是把一个集中式系统拆分成多个系统，每一个系统单独对外提供部分功能，整个分布式系统整体对外提供一整套服务。对于访问分布式系统的用户来说，感知上就像访问一台计算机一样。

分布式意味着可以采用更多的普通计算机（相对于昂贵的大型机）组成分布式集群对外提供服务。计算机越多，CPU、内存、存储资源等也就越多，能够处理的并发访问量也就越大。但是分布式系统中也存在着网络通信延迟、数据一致性等问题。

拿电商网站来说，我们一般把一个电商网站横向拆分成商品模块、订单模块、购物车模块、消息模块、支付模块等。然后我们把不同的模块部署到不同的机器上，各个模块之间通过远程服务调用(RPC)等方式进行通信。以一个分布式的系统对外提供服务。

**分布式（distributed）**是指在多台不同的服务器中部署不同的服务模块，通过远程调用协同工作，对外提供服务。

**集群（cluster）**是指在多台不同的服务器中部署相同应用或服务模块，构成一个集群，通过负载均衡设备对外提供服务。

#### 分布式系统的特征

分布式系统需要各个主机之间通信和协调主要通过网络进行，所以，分布式系统中的计算机在空间上几乎没有任何限制，这些计算机可能被放在不同的机柜上，也可能被部署在不同的机房中，还可能在不同的城市中，对于大型的网站甚至可能分布在不同的国家和地区。

但是，无论空间上如何分布，一个标准的分布式系统应该具有以下几个主要特征：
**分布性**
分布式系统中的多台计算机之间在空间位置上可以随意分布，系统中的多台计算机之间没有主、从之分，即没有控制整个系统的主机，也没有受控的从机。
**透明性**
系统资源被所有计算机共享。每台计算机的用户不仅可以使用本机的资源，还可以使用本分布式系统中其他计算机的资源(包括CPU、文件、打印机等)。
**同一性**
系统中的若干台计算机可以互相协作来完成一个共同的任务，或者说一个程序可以分布在几台计算机上并行地运行。
**通信性**

系统中任意两台计算机都可以通过通信来交换信息。

和集中式系统相比，分布式系统的性价比更高、处理能力更强、可靠性更高、也有很好的扩展性。但是，分布式在解决了网站的高并发问题的同时也带来了一些其他问题。首先，分布式的必要条件就是网络，这可能对性能甚至服务能力造成一定的影响。其次，一个集群中的服务器数量越多，服务器宕机的概率也就越大。另外，由于服务在集群中分布式部署，用户的请求只会落到其中一台机器上，所以，一旦处理不好就很容易产生数据一致性问题。

#### 什么是 CAP 理论，为什么不能同时满足？

●一致性 

每次读取都会收到最新的写入数据或错误信息。

●可用性 

每个请求都会收到（非错误的）响应，但不能保证响应包含最新的写入数据。

●分区容忍性 

尽管网络节点之间会丢弃（或延迟）任意数量的消息，系统仍然能够继续运行。

#### 什么是分布式 BASE 理论？

BASE 理论是对 CAP 理论的延伸，核心思想是即使无法做到强一致性（Strong Consistency，CAP的一致性就是强一致性），但应用可以采用适合的方式达到最终一致性（Eventual Consitency）。

BASE 是指基本可用（Basically Available）、软状态（ Soft State）、最终一致性（ Eventual Consistency）。

做不到 100% 可用，那么就做到基本可用。做不到强一致性，那么就做到最终一致性。

想要做到BASE，那么主要就是用这几个手段：**中间状态（软状态）+ 重试（最终一致性）+ 降级（基本可用）**

#### 什么是拜占庭将军问题？

拜占庭将军问题是分布式系统中的一个经典问题，由Leslie Lamport等人于1982年提出，是对分布式系统中节点之间进行协调的一种特殊情况的抽象描述。

拜占庭帝国的一支军队要攻打一个城市，攻打的成功需要不同将军协同决策，但是有些将军是不忠诚的，他们可能会发送虚假信息或者故意阻碍其他将军的决策。问题是如何让忠诚的将军在不知道其他将军是否忠诚的情况下做出正确的决策。

**拜占庭将军问题的本质是分布式系统中的协同问题，即如何使得分布式系统中的不同节点能够在相互独立的情况下达成共识。**这个问题对于分布式系统的可靠性和安全性具有重要的意义，同时也是分布式系统研究中的一个重要话题。

解决拜占庭将军问题有许多方法，比较常见的就是通过投票算法、共识算法来解决，但是这些算法其实背后都基于了一个思想，那就是超过半数。

**基于多数表决的解决方案：**假设总共有N个将军，每个将军发送自己的意见给其他将军，然后将军们根据收到的意见进行投票，如果有超过N/2个将军投票一致，则采取投票的结果。这个方案的前提是假设叛徒的数量不超过总将军数的一半，因为如果超过一半的将军都是叛徒，则无法保证多数投票的结果是正确的。这种解决方案在很多算法中都有实践，如 Raft、ZAB、Paxos 等。

#### 有了 2 阶段提交为什么还需要 3 阶段提交？

二阶段提交(Two-phaseCommit)是 XA 分布式事务中一个重要的方案，二阶段提交的算法思路可以概括为：参与者将操作成败通知协调者，再由协调者根据所有参与者的反馈情报决定各参与者是否要提交操作还是中止操作。

所谓的两个阶段是指：第一阶段：准备阶段(投票阶段)和第二阶段：提交阶段（执行阶段）。但是 2PC 本身存在着同步阻塞问题、单点故障问题、数据不一致问题等，所以在二阶段的基础上，增加了一个预提交的阶段，组成了3阶段提交的方案。

**XA规范**

X/Open 组织（即现在的 Open Group ）定义了分布式事务处理模型。 模型中主要包括应用程序（ AP ）、事务管理器（ TM ）、资源管理器（ RM ）、通信资源管理器（ CRM ）等四个角色。

一般，常见的事务管理器（ TM ）是交易中间件，常见的资源管理器（ RM ）是数据库，常见的通信资源管理器（ CRM ）是消息中间件。    

通常把一个数据库内部的事务处理，如对多个表的操作，作为本地事务看待。数据库的事务处理对象是本地事务，而分布式事务处理的对象是全局事务。

所谓全局事务，是指分布式事务处理环境中，多个数据库可能需要共同完成一个工作，这个工作即是一个全局事务，例如，一个事务中可能更新几个不同的数据库。对数据库的操作发生在系统的各处但必须全部被提交或回滚。此时一个数据库对自己内部所做操作的提交不仅依赖本身操作是否成功，还要依赖与全局事务相关的其它数据库的操作是否成功，如果任一数据库的任一操作失败，则参与此事务的所有数据库所做的所有操作都必须回滚。     

XA 就是 X/Open DTP 定义的交易中间件与数据库之间的接口规范（即接口函数），交易中间件用它来通知数据库事务的开始、结束以及提交、回滚等。 XA 接口函数由数据库厂商提供。 

二阶提交协议和三阶提交协议就是根据这一思想衍生出来的。可以说二阶段提交其实就是实现XA分布式事务的关键。

**2PC**

所谓的两个阶段是指：第一阶段：准备阶段(投票阶段)和第二阶段：提交阶段（执行阶段）。

在日常生活中其实是有很多事都是这种二阶段提交的，比如西方婚礼中就经常出现这种场景：

> 牧师：”你愿意娶这个女人吗?爱她、忠诚于她，无论她贫困、患病或者残疾，直至死亡。Doyou(你愿意吗)?”
> 新郎：”Ido(我愿意)!”
> 牧师：”你愿意嫁给这个男人吗?爱他、忠诚于他，无论他贫困、患病或者残疾，直至死亡。Doyou(你愿意吗)?”
> 新娘：”Ido(我愿意)!”
> 牧师：现在请你们面向对方，握住对方的双手，作为妻子和丈夫向对方宣告誓言。
> 新郎：我——某某某，全心全意娶你做我的妻子，无论是顺境或逆境，富裕或贫穷，健康或疾病，快乐或忧愁，我都将毫无保留地爱你，我将努力去理解你，完完全全信任你。我们将成为一个整体，互为彼此的一部分，我们将一起面对人生的一切，去分享我们的梦想，作为平等的忠实伴侣，度过今后的一生。
> 新娘：我全心全意嫁给你作为你的妻子，无论是顺境或逆境，富裕或贫穷，健康或疾病，快乐或忧愁，我都将毫无保留的爱你，我将努力去理解你，完完全全信任你，我们将成为一个整体，互为彼此的一部分，我们将一起面对人生的一切，去分享我们的梦想，作为平等的忠实伴侣，度过今后的一生。

![2阶段提交](./images/2阶段提交.png)

首先协调者（牧师）会询问两个参与者（二位新人）是否能执行事务提交操作（愿意结婚）。如果两个参与者能够执行事务的提交，先执行事务操作，然后返回 YES，如果没有成功执行事务操作，就返回 NO。

当协调者接收到所有的参与者的反馈之后，开始进入事务提交阶段。如果所有参与者都返回 YES，那就发送 COMMIT 请求，如果有一个人返回 NO，那就发送 rollback 请求。

值得注意的是，二阶段提交协议的第一阶段准备阶段不仅仅是回答 YES or NO，还是要执行事务操作的，只是执行完事务操作，并没有进行 commit 还是 rollback。和上面的结婚例子不太一样。如果非要举例的话可以理解为男女双方交换定情信物的过程。信物一旦交给对方了，这个信物就不能挪作他用了。也就是说，一旦事务执行之后，在没有执行 commit 或者 rollback 之前，资源是被锁定的。这会造成阻塞。

**2PC 存在的问题**

二阶段提交中，最重要的问题是可能会带来数据不一致的问题，除此之外，还存在同步阻塞以及单点故障的问题。

首先看为什么会发生同步阻塞和单点故障的问题：

1、同步阻塞问题。执行过程中，所有参与节点都是事务阻塞型的。当参与者占有公共资源时，其他第三方节点访问公共资源不得不处于阻塞状态。

2、单点故障。由于协调者的重要性，一旦协调者发生故障。参与者会一直阻塞下去。尤其在第二阶段，协调者发生故障，那么所有的参与者还都处于锁定事务资源的状态中，而无法继续完成事务操作。（如果是协调者挂掉，可以重新选举一个协调者，但是无法解决因为协调者宕机导致的参与者处于阻塞状态的问题）

作为一个分布式的一致性协议，我们主要关注他可能带来的一致性问题的。2PC 在执行过程中可能发生协调者或者参与者突然宕机的情况，在不同时期宕机可能有不同的现象。

**情况一：协调者挂了，参与者没挂**

这种情况其实比较好解决，只要找一个协调者的替代者。当他成为新的协调者的时候，询问所有参与者的最后那条事务的执行情况，他就可以知道是应该做什么样的操作了。所以，这种情况不会导致数据不一致。

**情况二：参与者挂了，协调者没挂**

这种情况其实也比较好解决。如果参与者挂了。那么之后的事情有两种情况：

- 第一个是挂了就挂了，没有再恢复。那就挂了呗，反正不会导致数据一致性问题。
- 第二个是挂了之后又恢复了，这时如果他有未执行完的事务操作，直接取消掉，然后询问协调者目前我应该怎么做，协调者就会比对自己的事务执行记录和该参与者的事务执行记录，告诉他应该怎么做来保持数据的一致性。

**情况三：参与者挂了，协调者也挂了**

这种情况比较复杂，我们分情况讨论。

- 协调者和参与者在第一阶段挂了。
  - 由于这时还没有执行 commit 操作，新选出来的协调者可以询问各个参与者的情况，再决定是进行 commit 还是 rollback。因为还没有 commit，所以不会导致数据一致性问题。
- 第二阶段协调者和参与者挂了，挂了的这个参与者在挂之前并没有接收到协调者的指令，或者接收到指令之后还没来的及做 commit 或者 rollback 操作。
  - 这种情况下，当新的协调者被选出来之后，他同样是询问所有的参与者的情况。只要有机器执行了abort（rollback）操作或者第一阶段返回的信息是No的话，那就直接执行 rollback 操作。如果没有人执行 abort 操作，但是有机器执行了 commit 操作，那么就直接执行 commit 操作。这样，当挂掉的参与者恢复之后，只要按照协调者的指示进行事务的 commit 还是 rollback 操作就可以了。因为挂掉的机器并没有做 commit 或者 rollback 操作，而没有挂掉的机器们和新的协调者又执行了同样的操作，那么这种情况不会导致数据不一致现象。
- 第二阶段协调者和参与者挂了，挂了的这个参与者在挂之前已经执行了操作。但是由于他挂了，没有人知道他执行了什么操作。
  - 这种情况下，新的协调者被选出来之后，如果他想负起协调者的责任的话他就只能按照之前那种情况来执行 commit 或者 rollback 操作。这样新的协调者和所有没挂掉的参与者就保持了数据的一致性，我们假定他们执行了 commit。但是，这个时候，那个挂掉的参与者恢复了怎么办，因为他之前已经执行完了之前的事务，如果他执行的是 commit 那还好，和其他的机器保持一致了，万一他执行的是 rollback 操作那？这不就导致数据的不一致性了么？虽然这个时候可以再通过手段让他和协调者通信，再想办法把数据搞成一致的，但是，这段时间内他的数据状态已经是不一致的了！

所以，2PC 协议中，如果出现协调者和参与者都挂了的情况，有可能导致数据不一致。

为了解决这个问题，衍生出了 3PC。我们接下来看看 3PC 是如何解决这个问题的。

**3PC**

3PC 最关键要解决的就是协调者和参与者同时挂掉的问题，所以 3PC 把 2PC 的准备阶段再次一分为二，这样三阶段提交就有 CanCommit、PreCommit、DoCommit 三个阶段。

![3PC](./images/3PC.png)

在第一阶段，只是询问所有参与者是否可以执行事务操作，并不在本阶段执行事务操作。当协调者收到所有的参与者都返回 YES 时，在第二阶段才执行事务操作，然后在第三阶段在执行 commit 或者 rollback。

**3PC 为什么比 2PC 好？**

直接分析前面我们提到的协调者和参与者都挂的情况。

> 第二阶段协调者和参与者挂了，挂了的这个参与者在挂之前已经执行了操作。但是由于他挂了，没有人知道他执行了什么操作。
>
> - 这种情况下，当新的协调者被选出来之后，他同样是询问所有的参与者的情况来决定是 commit 还是 rollback。这看上去和二阶段提交一样啊？他是怎么解决一致性问题的呢？
> - 看上去和二阶段提交的那种数据不一致的情况的现象是一样的，但仔细分析所有参与者的状态的话就会发现其实并不一样。我们假设挂掉的那台参与者执行的操作是 commit。那么其他没挂的操作者的状态应该是什么？他们的状态要么是 prepare-commit 要么是 commit。因为 3PC 的第三阶段一旦有机器执行了 commit，那必然第一阶段大家都是同意 commit。所以，这时，新选举出来的协调者一旦发现未挂掉的参与者中有人处于 commit 状态或者是 prepare-commit 的话，那就执行 commit 操作。否则就执行 rollback 操作。这样挂掉的参与者恢复之后就能和其他机器保持数据一致性了。（为了简单的让大家理解，笔者这里简化了新选举出来的协调者执行操作的具体细节，真实情况比我描述的要复杂）

简单概括一下就是，如果挂掉的那台机器已经执行了 commit，那么协调者可以从所有未挂掉的参与者的状态中分析出来，并执行 commit。如果挂掉的那个参与者执行了 rollback，那么协调者和其他的参与者执行的肯定也是 rollback 操作。

所以，再多引入一个阶段之后，3PC 解决了 2PC 中存在的那种由于协调者和参与者同时挂掉有可能导致的数据一致性问题。

**3PC 存在的问题**

在 doCommit 阶段，如果参与者无法及时接收到来自协调者的 doCommit 或者 rebort 请求时，会在等待超时之后，会继续进行事务的提交。

所以，由于网络原因，协调者发送的 abort 响应没有及时被参与者接收到，那么参与者在等待超时之后执行了 commit 操作。这样就和其他接到 abort 命令并执行回滚的参与者之间存在数据不一致的情况。

#### 分布式锁有几种实现方式？

分布式锁有多种实现方式，比较常见的实现是通过数据库、Redis 或者 Zookeeper 来实现的。

其中数据库的实现可以依赖悲观锁以及数据库表记录来实现，通过 Redis 的实现可以考虑使用 setnx、redission 以及 redlock 实现。使用 zk 主要是依赖他提供的临时有序节点来实现。

在分析这几种实现方案之前我们先来想一下，我们需要的分布式锁应该是怎么样的？

> 可以保证在分布式部署的应用集群中，同一个方法在同一时间只能被一台机器上的一个线程执行。
>
> 这把锁要是一把可重入锁（避免死锁）
>
> 这把锁最好是一把阻塞锁（根据业务需求考虑要不要这条）
>
> 有高可用的获取锁和释放锁功能
>
> 获取锁和释放锁的性能要好

**基于数据库实现分布式锁**

要实现分布式锁，最简单的方式可能就是直接创建一张锁表，然后通过操作该表中的数据来实现了。

当我们要锁住某个方法或资源时，我们就在该表中增加一条记录，想要释放锁的时候就删除这条记录。

创建这样一张数据库表：

```sql
CREATE TABLE `methodLock` (
  `id` int(11) NOT NULL AUTO_INCREMENT COMMENT '主键',
  `method_name` varchar(64) NOT NULL DEFAULT '' COMMENT '锁定的方法名',
  `desc` varchar(1024) NOT NULL DEFAULT '备注信息',
  `update_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '保存数据时间，自动生成',
  PRIMARY KEY (`id`),
  UNIQUE KEY `uidx_method_name` (`method_name `) USING BTREE
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='锁定中的方法';
```

当我们想要锁住某个方法时，执行以下SQL：

```sql
insert into methodLock(method_name,desc) values (‘method_name’,‘desc’)
```

因为我们对 method_name 做了唯一性约束，这里如果有多个请求同时提交到数据库的话，数据库会保证只有一个操作可以成功，那么我们就可以认为操作成功的那个线程获得了该方法的锁，可以执行方法体内容。

当方法执行完毕之后，想要释放锁的话，需要执行以下 Sql:

```sql
delete from methodLock where method_name ='method_name'
```

上面这种简单的实现有以下几个问题：

> 1、这把锁强依赖数据库的可用性，数据库是一个单点，一旦数据库挂掉，会导致业务系统不可用。
>
> 2、这把锁没有失效时间，一旦解锁操作失败，就会导致锁记录一直在数据库中，其他线程无法再获得到锁。
>
> 3、这把锁只能是非阻塞的，因为数据的insert操作，一旦插入失败就会直接报错。没有获得锁的线程并不会进入排队队列，要想再次获得锁就要再次触发获得锁操作。
>
> 4、这把锁是非重入的，同一个线程在没有释放锁之前无法再次获得该锁。因为数据中数据已经存在了。

当然，我们也可以有其他方式解决上面的问题。

- 数据库是单点？搞两个数据库，数据之前双向同步。一旦挂掉快速切换到备库上。
- 没有失效时间？只要做一个定时任务，每隔一定时间把数据库中的超时数据清理一遍。
- 非阻塞的？搞一个 while 循环，直到 insert 成功再返回成功。
- 非重入的？在数据库表中加个字段，记录当前获得锁的机器的主机信息和线程信息，那么下次再获取锁的时候先查询数据库，如果当前机器的主机信息和线程信息在数据库可以查到的话，直接把锁分配给他就可以了。

**基于数据库排他锁**

除了可以通过增删操作数据表中的记录以外，其实还可以借助数据中自带的锁来实现分布式的锁。

我们还用刚刚创建的那张数据库表。可以通过数据库的排他锁来实现分布式锁。 基于 MySql 的 InnoDB 引擎，可以使用以下方法来实现加锁操作：

```sql
public boolean lock(){
    connection.setAutoCommit(false)
    while(true){
        try{
            result = select * from methodLock where method_name=xxx for update;
            if(result==null){
                return true;
            }
        }catch(Exception e){

        }
        sleep(1000);
    }
    return false;
}
```

在查询语句后面增加 for update，数据库会在查询过程中给数据库表增加排他锁（这里再多提一句，InnoDB 引擎在加锁的时候，只有通过索引进行检索的时候才会使用行级锁，否则会使用表级锁。这里我们希望使用行级锁，就要给 method_name 添加索引，值得注意的是，这个索引一定要创建成唯一索引，否则会出现多个重载方法之间无法同时被访问的问题。重载方法的话建议把参数类型也加上。）。当某条记录被加上排他锁之后，其他线程无法再在该行记录上增加排他锁。

我们可以认为获得排它锁的线程即可获得分布式锁，当获取到锁之后，可以执行方法的业务逻辑，执行完方法之后，再通过以下方法解锁：

```java
public void unlock(){
    connection.commit();
}
```

通过 `connection.commit()` 操作来释放锁。

这种方法可以有效的解决上面提到的无法释放锁和阻塞锁的问题。

- 阻塞锁？ for update 语句会在执行成功后立即返回，在执行失败时一直处于阻塞状态，直到成功。
- 锁定之后服务宕机，无法释放？使用这种方式，服务宕机之后数据库会自己把锁释放掉。

但是还是无法直接解决数据库单点和可重入问题。

> 这里还可能存在另外一个问题，虽然我们对 method_name 使用了唯一索引，并且显示使用 for update 来使用行级锁。但是，MySql 会对查询进行优化，即便在条件中使用了索引字段，但是否使用索引来检索数据是由 MySQL 通过判断不同执行计划的代价来决定的，如果 MySQL 认为全表扫效率更高，比如对一些很小的表，它就不会使用索引，这种情况下 InnoDB 将使用表锁，而不是行锁。如果发生这种情况就悲剧了。。。
>
> 还有一个问题，就是我们要使用排他锁来进行分布式锁的lock，那么一个排他锁长时间不提交，就会占用数据库连接。一旦类似的连接变得多了，就可能把数据库连接池撑爆

**数据库实现分布式锁的优缺点**

总结一下使用数据库来实现分布式锁的方式，这两种方式都是依赖数据库的一张表，一种是通过表中的记录的存在情况确定当前是否有锁存在，另外一种是通过数据库的排他锁来实现分布式锁。

- 优点：直接借助数据库，容易理解。
- 缺点：
  - 会有各种各样的问题，在解决问题的过程中会使整个方案变得越来越复杂。
  - 操作数据库需要一定的开销，性能问题需要考虑。
  - 使用数据库的行级锁并不一定靠谱，尤其是当我们的锁表并不大的时候。

**基于缓存实现分布式锁**



**基于Zookeeper实现分布式锁**

基于 zookeeper 临时有序节点可以实现的分布式锁。

大致思想即为：每个客户端对某个方法加锁时，在zookeeper上的与该方法对应的指定节点的目录下，生成一个唯一的瞬时有序节点。 判断是否获取锁的方式很简单，只需要判断有序节点中序号最小的一个。 当释放锁的时候，只需将这个瞬时节点删除即可。同时，其可以避免服务宕机导致的锁无法释放，而产生的死锁问题。

> Zookeeper 实现的分布式锁其实存在一个缺点，那就是性能上可能并没有缓存服务那么高。因为每次在创建锁和释放锁的过程中，都要动态创建、销毁瞬时节点来实现锁功能。ZK 中创建和删除节点只能通过 Leader 服务器来执行，然后将数据同步到所有的 Follower 机器上。
>
> 其实，使用 Zookeeper 也有可能带来并发问题，只是并不常见而已。考虑这样的情况，由于网络抖动，客户端和 ZK 集群的 session 连接断了，那么 zk 以为客户端挂了，就会删除临时节点，这时候其他客户端就可以获取到分布式锁了。就可能产生并发问题。这个问题不常见是因为 zk 有重试机制，一旦 zk 集群检测不到客户端的心跳，就会重试，Curator 客户端支持多种重试策略。多次重试之后还不行的话才会删除临时节点。（所以，选择一个合适的重试策略也比较重要，要在锁的粒度和并发之间找一个平衡。）

优点：有效的解决单点问题，不可重入问题，非阻塞问题以及锁无法释放的问题。实现起来较为简单。

缺点：性能上不如使用缓存实现分布式锁。 需要对ZK的原理有所了解。

#### 什么是分布式事务？

分布式事务是指在分布式系统中涉及到多个数据库或多个应用程序之间的事务处理，这些数据库或应用程序可能分布在不同的物理节点上，甚至可能位于不同的地理位置。在分布式事务中，需要确保所有参与者的事务操作都能够保持一致性，即所有参与者的事务要么全部提交成功，要么全部回滚。

举个例子，假设一个电商系统，用户下单后需要扣减库存、扣减账户余额、生成订单等操作。在单机环境下，可以将这些操作放在同一个事务中，保证原子性、一致性和持久性。但在分布式环境下，可能存在多个服务（如库存服务、账户服务、订单服务）分布在不同的物理节点上，此时需要确保所有服务操作的事务都能够同步进行，避免出现数据不一致的情况。

为了解决分布式事务的问题，出现了一些分布式事务解决方案，如 XA 协议、TCC 事务、最大努力通知等。这些解决方案的实现方式各不相同，但都需要考虑如何确保所有参与者的事务操作能够保持一致性，以及如何处理可能出现的异常情况。

#### 常见的分布式事务有哪些？

分布式事务的目的是保证分布式系统中的多个参与方的数据能够保证一致性。即所有参与者，在一次写操作过程中要么都成功，要么都失败。

至于这个一致性到底是怎样的一致性，是强一致性、还是最终一致性，不同的分布式事务方案其实达到的效果并不相同。

如果想要实现强一致性，那么就一定要引入一个协调者，通过协调者来协调所有参与者来进行提交或者回滚。所以，这类方案包含基于XA规范的二阶段及三阶段提交、以及支持2阶段提交。

如果想要实现最终一致性，那么方案上就比较简单，常见的基于可靠消息的最终一致性（本地消息表、事务消息）、最大努力通知等。

#### 如何基于本地消息表实现分布式事务？

本地消息表其实也是借助消息来实现分布式事务的。

这个方案的主要思想是将分布式事务拆分为本地事务和消息事务两个部分，本地事务在本地数据库中进行提交或回滚，而消息事务则将消息写入消息中间件中，以实现消息的可靠投递和顺序性。

一般来说的做法是，在发送消息之前，先创建一条本地消息，并且保证写本地业务数据的操作，和，写本地消息记录的操作在同一个事务中。这样就能确保只要业务操作成功，本地消息一定可以写成功。

![分布式事务实现-本地消息表](./images/分布式事务实现-本地消息表-1.png)

然后再基于本地消息，调用 MQ 发送远程消息。

消息发出去之后，等待消费者消费，在消费者端，接收到消息之后，做业务处理，处理成功后再修改本地消息表的状态。

这个过程中，可能有几个步骤都可能发生失败，那么如果失败了怎么办呢？

1、2如果失败，因为在同一个事务中，所以事务会回滚，3及以后的步骤都不会执行。数据是一致的。

3如果失败，那么就需要有一个定时任务，不断的扫描本地消息数据，对于未成功的消息进行重新投递。

4、5如果失败，则依靠消息的重投机制，不断地重试。

6、7如果失败，那么就相当于两个分布式系统中的业务数据已经一致了，但是本地消息表的状态还是错的。这种情况也可以借助定时任务继续重投消息，让下游幂等消费再重新更改消息状态，或者本系统也可以通过定时任务去查询下游系统的状态，如果已经成功了，则直接推进消息状态即可。

![分布式事务实现-本地消息表-2](./images/分布式事务实现-本地消息表-2.png)

优点：

1. 可靠性高：基于本地消息表实现分布式事务，可以将本地消息的持久化和本地业务逻辑操作，放到一个事务中执行进行原子性的提交，从而保证了消息的可靠性。
2. 可扩展性好：基于本地消息表实现分布式事务，可以将消息的发送和本地事务的执行分开处理，从而提高了系统的可扩展性。
3. 适用范围广：基于本地消息表实现分布式事务，可以适用于多种不同的业务场景，可以满足不同业务场景下的需求。

缺点：

1. 实现复杂度高：基于本地消息表实现分布式事务，需要设计复杂的事务协议和消息发送机制，并且需要进行相应的异常处理和补偿操作，因此实现复杂度较高。
2. 系统性能受限：基于本地消息表实现分布式事务，需要将消息写入本地消息表，并且需要定时扫描本地消息表进行消息发送，因此对系统性能有一定影响。
3. 会带来消息堆积扫表慢、集中式扫表会影响正常业务、定时扫表存在延迟问题等问题。

#### 什么是最大努力通知？

所谓最大努力通知，换句话说就是并不保证100%通知到。这种分布式事务的方案，通常也是借助异步消息进行通知的。

发送者将消息发送给消息队列，接收者从消息队列中消费消息。在这个过程中，如果出现了网络通信故障或者消息队列发生了故障，就有可能导致消息传递失败，即消息被丢失。因此，最大努力通知无法保证每个接收者都能成功接收到消息，但是可以尽最大努力去通知。

下面是一个简单的例子来说明最大努力通知的过程。假设有一个在线商城系统，顾客可以下订单购买商品。当顾客成功下单后，通知顾客订单已经确认。这个通知就可以采用最大努力通知的方式。

- 顾客下单后，商城订单系统会生成订单并记录订单信息。
- 商城订单系统通过最大努力通知机制，将订单确认通知发送给用户通知服务。
- 用户通知服务把下单消息通过电子邮件发送给用户。
- 商城系统不会等待顾客的确认，而是将通知放入消息队列中，并尽力发送通知。
- 如果通知发送成功，那就很好，顾客会尽快收到订单确认邮件。但如果由于网络问题、电子邮件服务器问题或其他原因导致通知发送失败，商城系统可能会做一些尝试，尽可能的通知，重试多次后还是不成功，则不再发送

![最大努力通知](./images/最大努力通知.png)

需要注意的是，在最大努力通知的过程中，可能会出现消息重复发送的情况，也可能会出现消息丢失的情况。因此，在设计最大努力通知系统时，需要根据实际业务需求和风险承受能力来确定最大努力通知的策略和重试次数，以及对消息进行去重等处理。

最大努力通知这种事务实现方案，一般用在消息通知这种场景中，因为这种场景中如果存在一些不一致影响也不大。

> 最大努力通知和本地消息表区别？
>
> 本地消息表相对于最大努力通知而言，引入了本地消息表，通过本地事务来保证消息可以发送成功。相对来说，具有更强的可靠性，可以在一定程度上保证消息的传递不丢失。但是，本地消息表也会带来额外的存储开销和网络通信成本。
>
> 而最大努力通知这种方案比较简单，但是可能存在丢消息的情况。其实，一般业务中，也会通过对账来解决的，并不会完全放任消息丢失，只不过对账的机制会有一定的延时，并且可能需要人工介入。

#### 什么是 TCC，和 2PC 有什么区别？

TCC 是 Try-Confirm-Cancel 的缩写，它是一种分布式事务解决方案，采用了基于业务逻辑的补偿机制，将整个分布式事务分解为若干个子事务，每个子事务都有一个 try、confirm 和 cancel 三个操作，通过这些操作来实现分布式事务的执行和回滚。

![分布式事务实现-TCC](./images/分布式事务实现-TCC.png)

具体来说，TCC 事务包括以下三个步骤：

1. Try：在 try 阶段，参与者尝试执行本地事务，并对全局事务预留资源。如果 try 阶段执行成功，参与者会返回一个成功标识，否则会返回一个失败标识。
2. Confirm：如果所有参与者的 try 阶段都执行成功，则协调者通知所有参与者提交事务，那么就要执行 confirm 阶段，这时候参与者将在本地提交事务，并释放全局事务的资源。
3. Cancel：如果任何一个参与者在 try 阶段执行失败，则协调者通知所有参与者回滚事务。那么就要执行 cancel 阶段。

以下是一个简单的 TCC 事务的例子，假设有一个转账服务，需要从A账户中转移到B账户中100元、C账户中200元：

1. Try 阶段：转账服务首先尝试将A账户的金额冻结300元。
2. Confirm 阶段：如果所有的try操作都执行成功，转账服务将尝试执行解冻并转账，将金额转到B账户和C账户中。
3. Cancel 阶段：如果try过程中，某个转账事务执行失败。那么将执行解冻，将300元解冻。如果在confirm过程中，A->C的转账成功，但是A->B的转账失败，则再操作一次C->A的转账，将钱退回去。

TCC 这种事务方案有以下优缺点：

**优点：**

1. 灵活性：TCC适用于不同类型的业务场景，例如账户转账、库存扣减等，能够根据业务逻辑实现精细的事务控制。
2. 高可用性：TCC使用分布式锁来保证分布式事务的一致性，即使其中一个节点出现故障，也不会影响整个系统的运行。
3. 可扩展性：TCC 采用分阶段提交的方式，支持横向扩展，可以适应更多的并发访问和业务场景。
4. 性能：TCC 相对于 2PC 来说，具有更好的性能表现

**缺点：**

1. 实现复杂：TCC 需要实现 Try、Confirm 和 Cancel 三个操作，每个操作都需要实现正确的业务逻辑和补偿机制，代码实现比较复杂。
2. 存在悬挂事务问题：TCC的实现方式存在悬挂事务的问题，即在执行过程中可能会有部分子事务成功，而其他子事务失败，导致整个事务无法回滚或提交。
3. 空回滚问题：TCC 中的 Try 过程中，有的参与者成功了，有的参与者失败了，这时候就需要所有参与者都执行 Cancel，这时候，对于那些没有 Try 成功的参与者来说，本次回滚就是一次空回滚。需要在业务中做好对空回滚的识别和处理，否则就会出现异常报错的情况，甚至可能导致 Cancel 一直失败，最终导致整个分布式事务失败。
4. 业务代码侵入性：TCC 需要将事务操作拆分为 Try、Confirm 和 Cancel 三个步骤，对业务代码有一定的侵入性，需要针对不同的业务场景进行实现。

#### TCC 的空回滚和悬挂是什么？如何解决？

在 TCC 中，存在着两个比较关键的问题，那就是空回滚和悬挂的问题。

1. **空回滚问题：**TCC 中的 Try 过程中，有的参与者成功了，有的参与者失败了，这时候就需要所有参与者都执行 Cancel，这时候，对于那些没有Try成功的参与者来说，本次回滚就是一次空回滚。需要在业务中做好对空回滚的识别和处理，否则就会出现异常报错的情况，甚至可能导致 Cancel 一直失败，最终导致整个分布式事务失败。
2. **悬挂事务问题：**TCC 实现方式存在悬挂事务的问题，在调用 TCC 服务的一阶段 Try 操作时，可能会出现因网络拥堵而导致的超时，此时事务协调器会触发二阶段回滚，调用 TCC 服务的 Cancel 操作；在此之后，拥堵在网络上的一阶段 Try 数据包被 TCC 服务收到，出现了二阶段 Cancel 请求比一阶段 Try 请求先执行的情况。举一个比较常见的具体场景：一次分布式事务，先发生了 Try，但是因为有的节点失败，又发生了 Cancel，而下游的某个节点因为网络延迟导致先接到了 Cancel，在空回滚完成后，又接到了 Try 的请求，然后执行了，这就会导致这个节点的 Try 占用的资源无法释放，也没人会再来处理了，就会导致了事务悬挂。

这两个问题处理不好，都可能会导致一个分布式事务没办法保证最终一致性。有一个办法，可以一次性的解决以上两个问题，那就是——引入分布式事务记录表。

有了这张表，每一个参与者，都可以在本地事务执行的过程中，同时记录一次分布式事务的操作记录。

这张表中有两个关键的字段，一个是 tx_id 用于保存本次处理的事务 ID，还有一个就是 state，用于记录本次事务的执行状态。至于其他的字段，比如一些业务数据，执行时间、业务场景啥的，就自己想记录上就记录啥。

```sql
CREATE TABLE `distribute_transaction` (
  `tx_id` varchar(128) NOT NULL COMMENT '事务id',
  `state` int(1) DEFAULT NULL COMMENT '事务状态，0:try，1:confirm，2:cancel',
  PRIMARY KEY (`tx_id`) U
) 
```

有了这张表以后，我们在做 try、cancel 和 confirm 操作之后，都需要在本地事务中创建或者修改这条记录。一条记录的状态机如下：

**空回滚解决：**当一个参与者接到一次 Cancel 请求的时候，先去 distribute_transaction 中根据 tx_id 查询是否有 try 的记录，如果没有，则进行一次空回滚即可。并在 distribute_transaction 中创建一条记录，状态标记为 cancel。

**事务悬挂解决：**当一个参与者接到一次 Try 请求的时候，先去 distribute_transaction 表中根据 tx_id 查询是否有记录，如果当前存在，并且记录的状态是 cancel，则拒绝本次 try 请求。

但是需要注意的是，上面的请求过程，需要做好并发控制。

有了这张表，我们还可以基于他做幂等控制，每次 try-cancel-confirm 请求来的时候，都可以到这张表中查一下，然后做幂等控制。

#### TCC 中，Confirm 或者 Cancel 失败了怎么办？

在 TCC 模式中，如果 Confirm 阶段失败，这通常意味着在尝试提交事务的过程中遇到了问题。处理这种情况需要根据特定的失败场景和系统设计来确定最合适的策略。以下是几种常见的处理方法：
1. 重试（用的最多）
一种常见的策略是重试 Confirm 操作。这通常适用于由于临时问题（如网络延迟、服务短暂不可用等）导致的失败。在重试之前，可以设定一个延迟或等待一段时间，然后再次尝试 Confirm 操作。通常，会设置重试次数的上限，以避免无限重试。

这个方案用的是最多的，之所以可以这么做，主要是因为在 Try 的过程中已经锁定了资源，那么在 Confirm 的时候，大概率是可以成功，而如果 Confirm 失败就执行 Cancel，就会导致可能只是因为网络原因导致的时候就使得整个事务都 Cancel 了，而且这时候如果 Cancel 再失败怎么办呢？整个方案就会变得更加复杂了。

2. 执行 Cancel 操作
    如果重试 Confirm 操作依然失败，或者系统确定 Confirm 无法成功，下一步是执行 Cancel 操作。Cancel 阶段的目的是撤销在 Try 阶段预留的所有资源，确保系统回到事务开始前的状态。这是一种典型的回滚操作，用于处理事务失败的情况。

3. 日志记录和异常监控
    在 Confirm 失败的情况下，重要的是记录详细的错误日志和监控异常。这可以帮助系统管理员或开发人员分析为什么 Confirm 操作失败，并采取相应的改进措施。此外，日志可以帮助在事后定位问题的根源。

4. 人工干预
    在某些复杂或重要的事务中，如果自动化的重试和回滚失败，可能需要人工干预。这涉及到系统管理员或运维团队直接介入，手动处理故障和确保系统的一致性与稳定性。

**在 TCC 中，cancel 失败了怎么办呢？**

一般有以下几种处理手段，和 Confirm 也差不多，无非就是报警、重试、人工干预。

1. 记录日志&发送报警：将错误信息记录下来，方便后续分析和处理。并及时通知相关人员进行处理。
2. 自动重试：在一定程度上，可以通过自动重试的方式尝试多次执行 Cancel 操作，直到成功为止。
3. 人工干预：如果重试多次还是不成功， 可以报警，然后进行人工干预，可以尝试手动执行Cancel操作或者进行数据修复等。

#### TCC 和 2PC 有什么区别？

首先，二者的实现机制不同，2PC 使用协调者和参与者的方式来实现分布式事务，而 TCC 采用分阶段提交的方式。


处理方式不同，2PC 采用预写式日志的方式，在提交和回滚阶段需要协调者和参与者之间进行多次网络通信，整个事务处理过程较为复杂。TCC 则只需要在 Try、Confirm 和 Cancel 阶段执行相应的业务逻辑。

异常处理不同，2PC 需要处理网络、节点故障等异常情况，可能会导致整个事务无法提交或回滚，处理异常情况的复杂度较高。而TCC只需要处理业务异常情况，异常处理相对简单。

适用场景不同，2PC 适用于对事务一致性要求较高的场景，例如银行转账等，需要保证数据一致性和完整性。而 TCC 适用于对事务一致性要求不那么高的场景，例如电商库存扣减等，需要保证数据最终一致性即可。

> 最初 TCC 的设计是强一致性，基本上一次事务执行完之后，数据是一致的，要么都 commit，要么都 cancel。
>
> 但是其实在实际使用过程中，可能会采用最终一致性的思想，比如 commit 失败之后，进行异步重试让他尝试成功，而不是立刻 cancel

#### 什么是 Seata？他有哪几种模式？

Seata 是一个阿里开源的分布式事务解决方案（Simple Extensible Autonomous Transaction Architecture），用于在分布式系统中实现分布式事务。它旨在简化分布式事务的开发和管理，帮助解决分布式系统中的数据一致性问题。

|            | XA                             | AT                                     | TCC                                              | Saga                                                         |
| ---------- | ------------------------------ | -------------------------------------- | ------------------------------------------------ | ------------------------------------------------------------ |
| 一致性     | 强一致                         | 弱一致                                 | 弱一致                                           | 最终一致                                                     |
| 隔离性     | 完全隔离                       | 基于全局锁隔离                         | 基于资源预留隔离                                 | 无隔离                                                       |
| 代码侵入性 | 无                             | 无                                     | 有，要编写TCC三个接口                            | 有，要编写状态机及补偿代码                                   |
| 性能       | 差                             | 高                                     | 非常高                                           | 非常高                                                       |
| 适用场景   | 对一致性、隔离性要求较高的场景 | 基于关系型数据库的大多数分布式事务场景 | 对性能要求高的场景，有非关系型数据库要参与的事务 | 业务流程长且多。<br/>参与者包含外部接口或者遗留接口，无法做TCC模式的 |

**Seata 的实现原理**

因为 Seata 的开发者坚定地认为：一个分布式事务是有若干个本地事务组成的。所以他们给 Seata 体系的所有组件定义成了三种，分别是 Transaction Coordinator、Transaction Manager 和 Resource Manager

- **Transaction Coordinator(TC):**  这是一个独立的服务，是一个独立的 JVM 进程，里面不包含任何业务代码，它的主要职责：维护着整个事务的全局状态，负责通知 RM 执行回滚或提交；

- **Transaction Manager(TM):** 在微服务架构中可对应为聚合服务，即将不同的微服务组合起来成一个完成的业务流程，TM 的职责是开启一个全局事务或者提交或回滚一个全局事务；

- **Resource Manager(RM)：**RM 在微服务框架中对应具体的某个微服务为事务的分支，RM 的职责是：执行每个事务分支的操作。

看上去好像很难理解？举个例子你就知道了：

![Seata实现原理-1](./images/Seata实现原理-1.png)

在一个下单事务中，我们有一个聚合的服务，姑且把他叫做TradeCenter吧，他负责接收并处理用户的下单请求，并且下单过程中需要调用订单服务（Order）、库存服务（Stock）及账户服务（Account）进行创建订单、扣减库存及增加积分。

所以 TradeCenter 担当的就是 TM 的角色，而 Order、Stock 及 Account 三个微服务就是RM的角色。在此之外，还需要一个独立的服务，维护分布式事务的全局状态，他就是TC。

因为TC维护着整个事务的全局状态，负责通知 RM 执行回滚或提交，所以他和 TM、RM 都是有交互的。并且 TM 和 RM 之间也有调用关系。多个RM之间可以是独立的。

上面这个场景中，要想保证分布式事务，就需要 Order、Stock 及 Account 三个服务对应的数据库表操作，要么都成功、要么都失败。不能有部分成功、部分失败的情况。

在用了 Seata 之后，一次分布式事务的大致流程如下（不同的模式略有不同，在介绍具体模式的时候分别展开）：

1、TM 在接收到用户的下单请求后，会先调用 TC 创建一个全局事务，并且从 TC 获取到他生成的 XID。

2、TM 开始通过 `RPC/Restful` 调用各个 RM，调用过程中需要把 XID 同时传递过去。

![Seata实现原理-2](./images/Seata实现原理-2.png)

3、RM 通过其接收到的 XID,将其所管理的资源且被该调用锁使用到的资源注册为一个事务分支(Branch Transaction)

![Seata实现原理-3](./images/Seata实现原理-3.png)

4、当该请求的调用链全部结束时，TM根据本次调用是否有失败的情况，如果所有调用都成功，则决议 Commit，如果有超时或者失败，则决议 Rollback。

5、TM将事务的决议结果通知 TC，TC 将协调所有 RM 进行事务的二阶段动作，该回滚回滚，该提交提交。

![Seata实现原理-4](./images/Seata实现原理-4.png)

这里要求所有的 RM 都能做到 2 阶段，第一阶段做事务的预处理，第二阶段做事务的提交或者回滚。具体怎么实现，是否需要自己改代码，这个不同的模式不太一样。

#### 什么是柔性事务？

柔性事务，是业内解决分布式事务的主要方案。所谓柔性事务，相比较与数据库事务中的 ACID 这种刚性事务来说，柔性事务保证的是“基本可用，最终一致。”这其实就是基于 BASE 理论，保证数据的最终一致性。

虽然柔性事务并不像刚性事务那样完全遵循 ACID，但是，也是部分遵循 ACID 的，简单看一下关于 ACID 四个属性，柔性事务的支撑程度：

> 原子性：严格遵循
>
> 一致性：事务完成后的一致性严格遵循；事务中的一致性可适当放宽
>
> 隔离性：并行事务间不可影响；事务中间结果可见性允许安全放宽
>
> 持久性：严格遵循

在业内，关于柔性事务，最主要的有以下三种类型：**异步确保型、补偿型、最大努力通知型**。

> 想要实现柔性事务，有几个基础条件需要具备，以下介绍几个柔性事务实现的基础。

**可查询操作**

可查询操作，几乎是所有的分布式解决方案都需要的。

举一个常见的分布式场景的例子，如订单处理这一功能：

```java
/** 支付订单处理 **/
public void completeOrder() {
    orderDao.update(); // 订单服务本地更新订单状态
    accountService.update(); // 调用资金账户服务给资金帐户加款
    pointService.update(); // 调用积分服务给积分帐户增加积分
    accountingService.insert(); // 调用会计服务向会计系统写入会计原始凭证
    merchantNotifyService.notify(); // 调用商户通知服务向商户发送支付结果通知
}
```

以上这个支付订单处理的例子中，除了订单服务本地更新订单状态以外的所有操作，都需要调用 RPC 接口来执行，这种情况单纯的本地事务就无法保证数据的一致性了。就需要引入分布式事务。

在分布式事务执行过程中，如果某一个步骤执行出错，就需要明确的知道其他几个操作的处理情况，这就需要其他的服务都能够提供查询接口，保证可以通过查询来判断操作的处理情况。

![柔性事务-可查询操作](./images/柔性事务-可查询操作.png)

为了保证操作的可查询，需要对于每一个服务的每一次调用都有一个全局唯一的标识，可以是业务单据号（如订单号）、也可以是系统分配的操作流水号（如支付记录流水号）。除此之外，操作的时间信息也要有完整的记录。

**幂等操作**

幂等性，其实是一个数学概念。幂等函数，或幂等方法，是指可以使用相同参数重复执行，并能获得相同结果的函数，如：

    f(f(x)) = f(x)

在编程中一个幂等操作的特点是其任意多次执行所产生的影响均与一次执行的影响相同。也就是说，同一个方法，使用同样的参数，调用多次产生的业务结果与调用一次产生的业务结果相同。

这一个要求其实也比较好理解，因为要保证数据的最终一致性，很多解决防范都会有很多重试的操作，如果一个方法不保证幂等，那么将无法被重试。

幂等操作的实现方式有多种，如在系统中缓存所有的请求与处理结果、检测到重复操作后，直接返回上一次的处理结果等。

**可补偿操作**

提到事务，为了保证原子性，就可能发生 commit 和 rollback，那么在分布式事务中，要想进行 rollback，就需要提供可补偿操作。

比如上面的订单处理的例子中，在`调用积分服务给积分帐户增加积分`操作执行之后，经过分布式事务协调，最终决定回滚整个事务，那么就需要提供一个`调用积分服务给积分帐户扣减积分`的操作。

并且，补偿操作同时也需要满足幂等性。

**TCC 操作**

TCC 即 Try-Confirm-Cancel。

- Try: 尝试执行业务
  - 完成所有业务检查(一致性) 预留必须业务资源(准隔离性)
- Confirm: 确认执行业务
  - 真正执行业务 不作任何业务检查 只使用 Try 阶段预留的业务资源 Confirm 操作要满足幂等性
- Cancel: 取消执行业务
  - 释放 Try 阶段预留的业务资源 ，Cancel 操作要满足幂等性

这种类型和可补偿操作类似，就是提供一种提交和回滚的机制。是一种典型的两阶段类型的操作。这里说的两阶段类型操作并不是指 2PC，他和 2PC 还是有区别的。

#### 分布式 ID 生成方案都有哪些？

在单体应用中，我们可以通过数据库的主键ID来生成唯一的ID，但是如果数据量变大，就需要进行分库分表，在分库分表之后，如何生成一个全局唯一的 ID，就是一个关键的问题。

通常情况下，对于分布式 ID 来说，我们一般希望他具有以下几个特点：

- 全局唯一：必须保证全局唯一性，这个是最基本的要求。
- 高性能&高可用：需要保证ID的生成是稳定且高效的。
- 递增：根据不同的业务情况，有的会要求生成的 ID 呈递增趋势，也有的要求必须单调递增（后一个 ID 必须比前一个大），也有的没有严格要求。

通常，在分布式 ID 的生成方案主要有以下6种：

- UUID
- 数据库自增ID
- 号段模式
- 基于Redis 实现
- 雪花算法
- 第三方 ID 生成工具



**UUID**

UUID(Universally Unique Identifier) 全局唯一标识符，是指在一台机器上生成的数字，它保证对在同一时空中的所有机器都是唯一的。

标准的UUID格式为：xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx (8-4-4-4-12)，共32个字符，通常由以下几部分的组合而成：当前日期和时间，时钟序列，全局唯一的IEEE机器识别号

UUID的优点就是他的性能比较高，不依赖网络，本地就可以生成，使用起来也比较简单。

但是他也有两个比较明显的缺点，那就是长度过长和没有任何含义。长度自然不必说，他有32位16进制数字。对于"550e8400-e29b-41d4-a716-446655440000"这个字符串来说，我想任何一个程序员都看不出其表达的含义。一旦使用它作为全局唯一标识，就意味着在日后的问题排查和开发调试过程中会遇到很大的困难。

> 用 UUID 当做分布式 ID，存在着不适合范围查询、不方便展示以及查询效率低等问题。

**数据库自增**

分布式ID 也可以使用数据库的自增ID，但是这种实现中就要求一定是一个单库单表才能保证ID 自增且不重复，这就带来了一个单点故障的问题。

一旦这个数据库挂了，那整个分布式ID 的生成服务就挂了。而且还存在一个性能问题，如果高并发访问数据库的话，就会带来阻塞问题。

**号段模式**

号段模式是在数据库的基础上，为了解决性能问题而产生的一种方案。他的意思就是每次去数据库中取 ID 的时候取出来一批，并放在缓存中，然后下一次生成新 ID 的时候就从缓存中取。这一批用完了再去数据库中拿新的。

而为了防止多个实例之间发生冲突，需要采用号段的方式，即给每个客户端发放的时候按号段分开，如客户端A取的号段是1-1000，客户端B 取的是1001-2000，客户端C取的是2001-3000。当客户端A用完之后，再来取的时候取到的是3001-4000。

号段模式的好处是在同一个客户端中，生成的 ID 是顺序递增的。并且不需要频繁的访问数据库，也能提升获取 ID 的性能。缺点是没办法保证全局顺序递增，也存在数据库的单点故障问题。

其实很多分库分表的中间件的主键 ID 的生成，主要采用的也是号段模式，如 TDDL Sequence

**Redis 实现**

基于数据库可以实现，那么基于 Redis 也是可以的，我们可以依赖 Redis 的 incr 命令实现 ID 的原子性自增。

Redis 的好处就是可以借助集群解决单点故障的问题，并且他基于内存性能也比较高。

但是 Redis 存在数据丢失的情况，无论是那种持久化机制，都无法完全避免。

**雪花算法**

雪花算法（Snowflake）雪由 Twitter 研发的一种分布式 ID 生成算法，它可以生成全局唯一且递增的 ID。它的核心思想是将一个64 位的 ID 划分成多个部分，每个部分都有不同的含义，包括时间戳、数据中心标识、机器标识和序列号等。

具体来说，雪花算法生成的 ID 由以下几个部分组成：

1. 符号位（1bit）：预留的符号位，始终为0，占用1位。
2. 时间戳（41bit）：精确到毫秒级别，41位的时间戳可以容纳的毫秒数是2的41次幂，一年所使用的毫秒数是：365 * 24 * 60 * 60 * 1000，算下来可以使用69年。
3. 数据中心标识（5bit）：可以用来区分不同的数据中心。
4. 机器标识（5bit）：可以用来区分不同的机器。
5. 序列号（12bit)：可以生成4096个不同的序列号。

> SnowFlake 算法的缺点或者限制：
>
> 1、在 Snowflake 算法中，每个节点的机器ID 和数据中心ID 都是硬编码在代码中的，而且这些ID是全局唯一的。当某个节点出现故障或者需要扩容时，就需要更改其对应的机器ID 或数据中心ID，但是这个过程比较麻烦，需要重新编译代码，重新部署系统。还有就是，如果某个节点的机器ID 或数据中心ID 被设置成了已经被分配的ID，那么就会出现重复的ID，这样会导致系统的错误和异常。
>
> 2、Snowflake 算法中，需要使用 zookeeper 来协调各个节点的ID 	生成，但是 ZK 的部署其实是有挺大的成本的，并且 zookeeper 本身也可能成为系统的瓶颈。
>
> 3、依赖于系统时间的一致性，如果系统时间被回拨，或者不一致，可能会造成 ID 重复。

雪花算法使用时间戳作为生成 ID 的一部分，如果系统时钟回拨，可能会导致生成的ID重复。

时间回拨是指系统在运行过程中，可能由于网络时间校准或者人工设置，导致系统时间主动或被动地跳回到过去的某个时间

一旦发生这种情况，简单粗暴的做法是抛异常，发现时钟回调了，就直接抛异常出来。另外还有一种做法就是发现时钟变小了，就拒绝 ID 生成请求，等到时钟恢复到上一次的 ID 生成时间点后，再开始生成新的 ID。

美团 Leaf 引入了 Zookeeper 来解决时钟回拨问题，其大致思路为：每个 Leaf 运行时定时向 zk 上报时间戳。每次 Leaf 服务启动时，先校验本机时间与上次发 ID 的时间，再校验与 zk 上所有节点的平均时间戳。如果任何一个阶段有异常，那么就启动失败报警。

> 百度的 UidGenerator 中有两种 UidGenerator，其中 DefautlUidGenerator 使用了 System.currentTimeMillis() 获取时间与上一次时间比较，当发生时钟回拨时，抛出异常。而 CachedUidGenerator 使用是放弃了对机器的时间戳的强依赖，而是改用 AtomicLong 的 incrementAndGet() 来获取下一次时间，从而脱离了对服务器时间的依赖。

**第三方工具**

除了以上方案以外，还有一些第三方的工具可以用来实现分布式ID，如百度的 UidGenerator、美团的 Leaf 以及滴滴的 Tinyid 等等。

这些框架在功能上有的是整合了我们前面提到的多种实现方式，有的是针对不同的方式做了改进，如解决雪花算法的时钟拨回问题等。

#### 怎么实现分布式 Session？

在分布式系统中，我们的应用可能是以集群形式对外提供服务的，有可能出现在A服务器登录后，用户下一次访问的时候请求到B服务器，就需要有一个分布式的 Sesssion 来告诉 B 服务器用户是登录过的，并且需要拿到用户的登录信息。

在业内，实现分布式 Session 通常有以下几个方案：

客户端存储：用户登录后，将 Session 信息保存在客户端，用户在每次请求的时候，通过客户端的 cookie 把 session 信息带过来。这个方案因为要把 session 暴露给客户端，存在安全风险。

基于分布式存储（最常用）：将 Session 数据保存在分布式存储系统中，如分布式文件系统、分布式数据库等。不同服务器可以共享同一个分布式存储，通过 Session ID 查找对应的 Session 数据。唯一的缺点就是需要依赖第三方存储，如 Redis、数据库等。

粘性 Session：这个方案指的是把一个用户固定的路由到指定的机器上，这样只需要这台服务器中保存了 session 即可，不需要做分布式存储。但是这个存在的问题就是可能存在单点故障的问题。

Session 复制：当用户的 Session 在某个服务器上产生之后，通过复制的机制，将他同步到其他的服务器中。这个方案的缺点是有可能有延迟。

Tomcat 支持 Session 复制，配置方式可以参考官方文档：https://tomcat.apache.org/tomcat-8.0-doc/cluster-howto.html

Spring 中也提供了对 Session 管理的支持 —— Spring Session，他集成了很多 Session 共享的方案，如基于 Redis、基于数据库等。

#### 分布式命名方案都有哪些？

命名服务，就是帮助我们对资源进行命名的服务，命名的目的当然是为了更好的定位了。这里所提到的资源在不同场景中包括但不限于计算机（主机）名和地址、应用提供的服务的地址或者远程对象等。

一些比较常见的分布式框架（RPC、RMI）等都需要用到命名服务，如何解决分布式场景中的统一命名是一个至关重要的话题。

常见的命名方案有 JNDI、数据库自增 ID、UUID 以及基于 zookeeper 的命名服务来实现。

#### 什么是负载均衡，有哪些常见算法？

为了提升web应用的各方面能力，我们一般会把多台机器组成一个集群对外提供服务。然而，我们的网站对外提供的访问入口都是一个的，比如www.54p.com。那么当用户在浏览器输入www.54p.com的时候如何将用户的请求分发到集群中不同的机器上呢，这就是负载均衡在做的事情。

**负载均衡（Load Balance），意思是将负载（工作任务，访问请求）进行平衡、分摊到多个操作单元（服务器，组件）上进行执行。是解决高性能，单点故障（高可用），扩展性（水平伸缩）的终极解决方案。**

负载均衡服务器在决定将请求转发到具体哪台真实服务器的时候，是通过负载均衡算法来实现的。负载均衡算法，是一个负载均衡服务器的核心。

负载均衡算法可以分为两类：静态负载均衡算法和动态负载均衡算法。

静态负载均衡算法包括：轮询，比率，优先权

动态负载均衡算法包括: 最少连接数,最快响应速度，观察方法，预测法，动态性能分配，动态服务器补充，服务质量，服务类型，规则模式。

> 【负载均衡分类】
>
> 想要实现负载均衡，其实有很多种做法，在深入介绍负载均衡之前，要先介绍一个概念，那就是OSI七层模型。
>
> OSI 是一个开放性的通信系统互连参考模型，他是一个定义得非常好的协议规范。
>
> OSI 模型有 7 层结构，每层都可以有几个子层。 OSI 的 7 层从上到下分别是 
> 7、应用层；
> 6、表示层；
> 5、会话层；
> 4、传输层；
> 3、网络层；
> 2、数据链路层；
> 1、物理层；

其中高层（即7、6、5、4层）定义了应用程序的功能，下面3层（即3、2、1层）主要面向通过网络的端到端的数据流。

在这七层模型种，高层次都是依赖于低层次的。层次越高，使用起来越方便。

![OSI网络7层模型](./images/OSI网络7层模型.png)

了解了网络协议的七层模型以后，再来看看负载均衡。我们可以很明确的一点是，负载均衡是要在网络传输中做文章的。而要在网络传输过程搞事情，那么这七层模型就势必躲不开。

所以，根据负载均衡技术实现在 OSI 七层模型的不同层次，是可以给负载均衡分类的。

常见的实现方式中，主要可以在应用层、传输层、网络层和数据传输层做文章。所以，工作在应用层的负载均衡，我们通常称之为七层负载均衡、工作在传输层的我们称之为四层负载均衡。

大致可以分为以下几种，其中最常用的是四层和七层负载均衡：

**二层负载均衡** 

负载均衡服务器对外依然提供一个 VIP（虚IP），集群中不同的机器采用相同 IP 地址，但是机器的 MAC 地址不一样。当负载均衡服务器接受到请求之后，通过改写报文的目标MAC地址的方式将请求转发到目标机器实现负载均衡。

**三层负载均衡**

和二层负载均衡类似，负载均衡服务器对外依然提供一个 VIP（虚IP），但是集群中不同的机器采用不同的 IP 地址。当负载均衡服务器接受到请求之后，根据不同的负载均衡算法，通过 IP 将请求转发至不同的真实服务器。

**四层负载均衡** 

四层负载均衡工作在 OSI 模型的传输层，由于在传输层，只有 TCP/UDP 协议，这两种协议中除了包含源 IP、目标 IP 以外，还包含源端口号及目的端口号。四层负载均衡服务器在接受到客户端请求后，以后通过修改数据包的地址信息（IP + 端口号）将流量转发到应用服务器。

**七层负载均衡** 

七层负载均衡工作在 OSI 模型的应用层，应用层协议较多，常用 http、radius、dns 等。七层负载就可以基于这些协议来负载。这些应用层协议中会包含很多有意义的内容。比如同一个Web服务器的负载均衡，除了根据 IP 加端口进行负载外，还可根据七层的URL、浏览器类别、语言来决定是否要进行负载均衡。

> 负载均衡工具
>
> 市面上有很多开源的负载均衡的工具或软件，基本都是基于前面提到的方案实现的，大多数是工作在第七层和第四层的。Nginx/LVS/HAProxy 是目前使用最广泛的三种负载均衡软件。

**LVS** 

LVS（Linux Virtual Server），也就是 Linux 虚拟服务器, 是一个由章文嵩博士发起的自由软件项目。使用 LVS 技术要达到的目标是：通过 LVS 提供的负载均衡技术和 Linux 操作系统实现一个高性能、高可用的服务器群集，它具有良好可靠性、可扩展性和可操作性。从而以低廉的成本实现最优的服务性能。

LVS 主要用来做四层负载均衡。

**Nginx** 

Nginx（发音同engine x）是一个网页服务器，它能反向代理 HTTP, HTTPS, SMTP, POP3, IMAP 的协议链接，以及一个负载均衡器和一个 HTTP 缓存。

Nginx 主要用来做七层负载均衡。

**HAProxy** 

HAProxy 是一个使用 C 语言编写的自由及开放源代码软件，其提供高可用性、负载均衡，以及基于 TCP 和 HTTP 的应用程序代理。

HAProxy 主要用来做七层负载均衡。

#### 常见负载均衡算法

负载均衡服务器在决定将请求转发到具体哪台真实服务器的时候，是通过负载均衡算法来实现的。负载均衡算法，是一个负载均衡服务器的核心。

负载均衡算法可以分为两类：静态负载均衡算法和动态负载均衡算法。

静态负载均衡算法包括：轮询，比率，优先权

动态负载均衡算法包括: 最少连接数,最快响应速度，观察方法，预测法，动态性能分配，动态服务器补充，服务质量，服务类型，规则模式。

- 轮询（Round Robin）：顺序循环将请求一次顺序循环地连接每个服务器。当其中某个服务器发生第二到第7 层的故障，BIG-IP 就把其从顺序循环队列中拿出，不参加下一次的轮询，直到其恢复正常。
- 比率（Ratio）：给每个服务器分配一个加权值为比例，根椐这个比例，把用户的请求分配到每个服务器。当其中某个服务器发生第二到第7 层的故障，BIG-IP 就把其从服务器队列中拿出，不参加下一次的用户请求的分配, 直到其恢复正常。
- 优先权（Priority）：给所有服务器分组,给每个组定义优先权，BIG-IP 用户的请求，分配给优先级最高的服务器组（在同一组内，采用轮询或比率算法，分配用户的请求）；当最高优先级中所有服务器出现故障，BIG-IP 才将请求送给次优先级的服务器组。这种方式，实际为用户提供一种热备份的方式。
- 最少的连接方式（Least Connection）：传递新的连接给那些进行最少连接处理的服务器。当其中某个服务器发生第二到第7 层的故障，BIG-IP 就把其从服务器队列中拿出，不参加下一次的用户请求的分配, 直到其恢复正常。
- 最快模式（Fastest）：传递连接给那些响应最快的服务器。当其中某个服务器发生第二到第7 层的故障，BIG-IP 就把其从服务器队列中拿出，不参加下一次的用户请求的分配，直到其恢复正常。
- 观察模式（Observed）：连接数目和响应时间以这两项的最佳平衡为依据为新的请求选择服务器。当其中某个服务器发生第二到第7 层的故障，BIG-IP就把其从服务器队列中拿出，不参加下一次的用户请求的分配，直到其恢复正常。
- 预测模式（Predictive）：BIG-IP利用收集到的服务器当前的性能指标，进行预测分析，选择一台服务器在下一个时间片内，其性能将达到最佳的服务器相应用户的请求。(被BIG-IP 进行检测)
- 动态性能分配(Dynamic Ratio-APM):BIG-IP 收集到的应用程序和应用服务器的各项性能参数，动态调整流量分配。
- 动态服务器补充(Dynamic Server Act.):当主服务器群中因故障导致数量减少时，动态地将备份服务器补充至主服务器群。
- 服务质量(QoS）:按不同的优先级对数据流进行分配。
- 服务类型(ToS): 按不同的服务类型（在Type of Field中标识）负载均衡对数据流进行分配。
- 规则模式：针对不同的数据流设置导向规则，用户可自行。

以上，就是目前实现负载均衡的主流算法。不同的负载均衡服务器会选择不同的算法。就像电影院和火车站可能会选用不同的引导策略一样。火车站可能会把行李少的旅客分配到一个专门的入口，可能给即将发车的旅客分派到特快入口，手持可扫描车票的用户单独分配到特殊入口等。

#### 如何解决接口幂等的问题？

解决接口幂等问题，只需要记住一句口令**"一锁、二判、三更新"**，只要严格遵守这个过程，那么就可以解决并发问题。

- 一锁：第一步，先加锁。可以加分布式锁、或者悲观锁都可以。但是一定要是一个互斥锁！
- 二判：第二步，进行幂等性判断。可以基于状态机、流水表、唯一性索引等等进行重复操作的判断。
- 三更新：第三步，进行数据的更新，将数据进行持久化。

```java
//一锁：先加一个分布式锁
@DistributeLock(scene = "OEDER", keyExpression = "#request.identifier", expire = 3000)
public OrderResponse apply(OrderRequest request) {
    OrderResponse response = new OrderResponse();
  	//二判：判断请求是否执行成功过
    OrderDTO orderDTO = orderService.queryOrder(request.getProduct(), request.getIdentifier());
    if (orderDTO != null) {
        response.setSuccess(true);
        response.setResponseCode("DUPLICATED");
        return response;
    }

		//三更新：执行更新的业务逻辑
  	return orderService.order(request);
}
```

三步需要严格控制顺序，确保加锁成功后进行数据查询和判断，幂等性判断通过后再更新，更新结束后释放锁。

以上操作需要有一个前提，那就是第一步加锁、和第二步判断的时候，需要有一个依据，这个就是幂等号了，通常需要和上游约定一个唯一ID 作为幂等号。然后通过对幂等号加锁，再通过幂等号进行幂等判断即可。

一锁这个过程，建议使用 Redis 实现分布式锁，因为他是非阻塞的高效率的互斥锁。非常适合在幂等控制场景中。

二判这个过程，如果有操作流水，建议基于操作流水做幂等，并将幂等号作为唯一性约束，确保唯一性。如果没有流水，那么基于状态机也是可以的。

但是不管怎么样，数据库的唯一性约束都要加好，这是系统的最后一道防线。万一前面的锁失效了，这里也能控制得住不会产生脏数据。

> 第一步加锁为了解决高并发场景下的幂等问题，如果没有高并发， 不需要第一步了，就直接查询，更新，再更新的时候做乐观锁控制就行了

#### 为什么不建议用数据库唯一性约束做幂等控制？

在做幂等控制的时候，通常会选择基于数据库的唯一性约束来做，一般流程是这样的：

1、根据幂等字段查询是否有历史记录
2、如果有，则直接返回
3、如果没有，则执行数据库操作，并捕获数据库唯一性约束冲突异常
4、没有异常，返回成功
5、捕获到异常，反查一下数据，如果真的成功，则返回成功

```java
public Boolean createUser(User user){

    User existUser = userDao.getUserByTel(user.getTelephone());
    
    if(existUser){
        return true;
    }
    
    try{
        return userDao.insert(user);
    }catch(DuplicateKeyException e){
        User existUser = userDao.getUserByTel(user.getTelephone());
        if(existUser){
            return true;
        }
    }
    
    return false;
}
```

首先我们说，这么做肯定是可以的，没啥大问题，一些小项目中，这么用也都是OK的。

但是为啥有人不建议这么做呢？或者说这么做有啥问题呢？为啥还需要一锁二判三更新呢？

> 这个方案，主要有以下几个问题：

**1、依赖 insert**，以上的方案，有一个局限性，就是需要在做 insert 的时候才行，这种情况下会因为幂等操作导致重复记录，而出发唯一性约束冲突。（不是说 update 不会触发，而是一般业务的 update 操作都不太会导致这种情况发生）

**2、依赖异常**，这里是通过 catch 了 DuplicateKeyException 依赖来做的处理，这样就对异常有了依赖，不建议大家在代码中根据异常来控制业务流程（原文见下方链接），另外，这里和 DuplicateKeyException 绑定了，一旦有一天换了数据库、换了 ORM 框架，换了 Spring 版本等等，这个异常就可能会发生改变，也许就不再抛这个异常了，那么就会出现问题。

**3、依赖数据库**，这种做法，还有一个问题，就是把并发请求交给数据库来抗了，如果没有特别大的并发的话没啥问题，但是如果一旦有并发比较高的话，那么就可能会对数据库造成很大的压力。

> 当然，这个做法也有好处，一方面是简单，不需要额外的引入分布式锁，还有一个好处，就是大多数情况下，其实业务幂等场景中出现并发或者重复的概率并不大，所以走到这个catch的流程也并不多，这样做相比先加个锁要更加高效。
>
> 所以，如果并发冲突不高，并且是insert操作，能基于唯一性约束来做的话，也可以这么干。但是不建议！如果并发比较高，那么建议还是一锁二判三更新。

#### Leaf生成分布式ID的原理？

Leaf 是美团的分布式 ID 框架，他有 2 种生成 ID 的模式，分别是 Snowflake 和 Segment。

在 Segment（号段）模式中，他的意思就是每次去数据库中取ID 的时候取出来一批，并放在缓存中，然后下一次生成新 ID 的时候就从缓存中取。这一批用完了再去数据库中拿新的。

而为了防止多个实例之间发生冲突，需要采用号段的方式，即给每个客户端发放的时候按号段分开，如客户端 A 取的号段是 1-1000，客户端 B 取的是 1001-2000，客户端 C 取的是 2001-3000。当客户端 A 用完之后，再来取的时候取到的是 3001-4000。

号段模式的好处是在同一个客户端中，生成的ID是顺序递增的。并且不需要频繁的访问数据库，也能提升获取ID的性能。

> 这种模式的优点是，虽然依赖数据库，但是因为有号段缓存，所以在数据库宕机后的一段时间内也能保证可用性，并且这种模式不依赖时钟，所以不存在时钟回拨的问题。
>
> 缺点也比较明显，首先是如果多个缓存中刚好用完了号段，同时去请求数据库获取新的号段时可能会导致并发争抢影响性能，另外，DB 如果宕机时间过长，缓存中号段耗尽也会有可用性问题。
>
> 为了解决多个号段用完之后取新的号段冲突，Leaf 还引入了双 buff，当号段消费到某个阈值时就异步的把下一个号段加载到内存中，而不需要定好耗尽才去更新，这样可以避免取号段的时候导致没有号码分配影响可用性及性能。

在 **Snowflake 模式**中，当然是基于基于 Twitter 的 Snowflake 算法实现的了。但是主要是针对 Snowflake 中存在的一些问题做了很多优化：

1、数据中心ID 和机器ID 的配置方式：Snowflake 需要在代码中硬编码数据中心ID 和机器ID，而 Leaf 通过配置文件的方式进行配置，可以动态配置数据中心ID 和机器ID，降低了配置的难度。

2、引入区间概念：Leaf 引入了区间的概念，每次从 zookeeper 获取一段 ID 的数量（比如1万个），之后在这个区间内产生ID，避免了每次获取ID 都要去 zookeeper 中获取，减轻了对 zookeeper 的压力，并且也可以减少对 ZK 的依赖，并且也能提升生成ID 的效率。

3、自适应调整：Leaf 支持自适应调整ID 生成器的参数，比如每个区间的 ID 数量、ID 生成器的工作线程数量等，可以根据实际情况进行动态调整，提高了系统的性能和灵活性。

4、支持多种语言：Leaf 不仅提供了 Java 版本的 ID 生成器，还提供了 Python 和 Go 语言的版本，可以满足不同语言的开发需求。

5、时钟回拨解决：每个 Leaf 运行时定时向 zk 上报时间戳。每次 Leaf 服务启动时，先校验本机时间与上次发 ID 的时间，再校验与 zk 上所有节点的平均时间戳。如果任何一个阶段有异常，那么就启动失败报警。

> Leaf 的分布式ID 生成过程可以简述如下：

1、Leaf 生成器启动时，会从配置文件中读取配置信息，包括数据中心 ID、机器 ID 等。

2、Leaf 生成器会向 zookeeper 注册自己的信息，包括 IP 地址、端口号等。
3、应用程序需要生成一个 ID 时，会向 Leaf 生成器发送一个请求。

4、Leaf 生成器会从 zookeeper 中读取可用的区间信息，并分配一批 ID。

5、Leaf 生成器将分配的 ID 返回给应用程序。

6、应用程序可以使用返回的 ID 生成具体的业务 ID。

7、当分配的 ID 用完后，Leaf 生成器会再次向 zookeeper 请求新的区间。

#### 什么是一致性哈希？

哈希算法大家都不陌生，经常被用在负载均衡、分库分表等场景中，比如说我们在做分库分表的时候，最开始我们根据业务预估，把数据库分成了 128 张表，这时候要插入或者查询一条记录的时候，我们就会先把分表键，如 buyer_id 进行 hash 运算，然后再对 128 取模，得到 0-127 之间的数字，这样就可以唯一定位到一个分表。

但是随着业务得突飞猛进，128 张表，已经不够用了，这时候就需要重新分表，比如增加一张新的表。这时候如果采用 hash 或者取模的方式，就会导致 128+1 张表的数据都需要重新分配，成本巨高。

而一致性 hash 算法， 就能有效的解决这种分布式系统中增加或者删除节点时的失效问题。

**一致性哈希（Consistent Hashing）是一种用于分布式系统中数据分片和负载均衡的算法。它的目标是在节点的动态增加或删除时，尽可能地减少数据迁移和重新分布的成本。**

> 在总结一下。一致性哈希算法将整个哈希空间视为一个环状结构，将节点和数据都映射到这个环上。每个节点通过计算一个哈希值，将节点映射到环上的一个位置。而数据也通过计算一个哈希值，将数据映射到环上的一个位置。
>
> 当有新的数据需要存储时，首先计算数据的哈希值，然后顺时针或逆时针在环上找到最近的节点，将数据存储在这个节点上。当需要查找数据时，同样计算数据的哈希值，然后顺时针或逆时针在环上找到最近的节点，从该节点获取数据。

#### 如何实现应用中的链路追踪？

随着业务量的增长，为了提升整体系统的可用性、性能及可扩展性，很多大型互联网公司都会采用微服务架构，一次业务请求，一般要经过几个微服务调用才能完成，。

一次请求之间要经过很多的系统，那么如何追踪一次请求从头到尾的流程，就至关重要，这样可以帮我们做很好的链路分析，及问题定位。

在业内，有很多链路追踪的工具，如 Google 的 dapper、twitter 的 zipkin、京东的 hydra、大众点评的 cat，以及开源的 skywalking。

> 不管是哪个实现，在我看来重点就是解决两个问题：
>
> 1、生成一个全局的 traceId
> 2、把这个 traceId 传递下去

**生成 TraceId**

想要追踪一个完成的链路，就需要有一个标识来标记这次调用链，业内把他叫做 traceId，一般会在入口处生成一个全局唯一的 traceId，比如说在HTTP的请求入口，在定时任务的调度入口等，生成一个 traceId。

**传递 TraceId**

在有了一个 traceId 之后，想要通过它把一次调用过程串联起来，那么就需要所有的系统间调用都得把他传递下去，这里面的调用包括了 HTTP 请求、RPC 请求、MQ 消息等，甚至还需要涉及到 Redis、MySQL 等等可能都需要进行传递。

所以，想要实现一个链路追踪，需要很多中间件一起配合才行，通常这个 traceId 会存放在 RPC 的请求头、HTTP 的请求头、MQ消息的消息头中进行传递。

系统之间通过这种方式，那系统内部也是需要传递的，所以一般都是用 ThreadLocal 来实现的，在接收到请求后，会把这个 traceId 存储在 ThreadLocal 中，然后就能在当前线程中一直传递下去，并且在记录日志的时候取出来打印到日志中，在需要调远程的时候，取出来传递下去。

> 但是，如果有多线程怎么办呢？ThreadLocal 咋传递呢，这就要用到TTL了：
>
> TransmittableThreadLocal 是阿里开源的一个方案 （开源地址：https://github.com/alibaba/transmittable-thread-local ） ，这个类继承并加强 InheritableThreadLocal 类。用来实现线程之间的参数传递。

**Span**

前面提到了 traceId，其实光有 traceId 还不够，trace 帮我们把一次调用串联起来，但是一次调用在每一个系统上都干了什么，干了多久，成功还是失败，这些对我们来说也很重要，这些信息就被记录在 span 中。

通常一个完整的 Span 具有如下属性：

- Operation Name：描述了当前接口的行为语义，如具体的哪个接口，哪个URL地址。
- SpanId/ParentSpanId：接口调用的层级标识，用于还原 Trace 内部的层次调用关系。
- Start/FinishTime：接口调用的开始和结束时间，二者相减就是该次调用的耗时。
- StatusCode：响应状态，标识当次调用是成功或失败。
- Tags & Events：调用附加信息

#### 实现一个分布式锁需要考虑哪些问题？

想要实现一个分布式锁，一般需要考虑哪些问题？一般来说应该从以下几个方面来考虑：

**互斥性**

一个分布式锁，最基本的要求，就是要具备互斥性，同一时间只能有一个线程获取到锁。否则就会出现并发问题。

在分布式场景中，想要实现一个分布式锁，必须要依赖一个第三方的分布式组件，比如数据库、Redis 或者 Zookeeper。借助自带的锁机制、单线程、互斥性等特点来实现互斥性。

**避免死锁**

锁的死锁问题使我们不得不考虑的。尤其在在分布式环境中，由于网络延迟、节点故障等原因，会出现死锁的概率就会更高。所以我们在设计分布式锁的时候，一般都会设置一定的超时机制和死锁检测策略。

**阻塞&非阻塞**

根据加锁失败后是否阻塞持续自旋加锁，分布式锁可以分为阻塞锁和非阻塞锁。一般来说非阻塞锁用的比较多。像我们常用的 Redis 的分布式锁就是非阻塞锁。而使用数据库悲观锁 for update 实现的可能就是个阻塞锁，这个要根据业务的具体情况来做选择和设计。

**可重入**

一个线程，拿到锁之后，是否可以在未释放时重新获得锁。这就是可重入的特性了。可重入的锁不仅可以提升加锁效率，也能降低死锁的概率。

而且在有些业务场景中，对是否可以重入也会有一些要求。所以这个也是需要重点考量的。

**锁的性能**

加锁性能是很重要的，尤其是分布式锁。因为在用分布式锁的场景一般并发较高，而如果分布式锁自身的性能差的话，对业务来说也是不可接受的。所以好的性能更重要。

**可靠性**

一个分布式锁是否可靠，很重要，一旦他不可靠了，就可能会出现重复加锁导致并发问题。这也是为什么Redis 的分布式锁从 SetNX 到 Redisson 再到 RedLock 的重要原因。

**其他**

实现一个分布式锁，除了上面这些，还有一些其他的东西需要考虑，比如实现的复杂度、易用性等，都很重要的。

#### 定时任务扫表的缺点有什么？

本地消息表的分布式事务方案是依赖本地消息表，然后通过定时任务扫表的方式来实现的最终一致性。那么这个方案，整体上来看，在以下几个方面是有问题的：

1、消息堆积扫表慢
2、集中式扫表会影响正常业务
3、定时扫表存在延迟问题

那么，这几个问题，该如何解决呢？



**消息堆积，扫表慢**

随着本地消息表中的数据量越来越大，通过定时任务扫表的方式会越来越慢，那么想要解决这个问题，首先可以考虑加索引。

我们可以在 state 字段上增加一个索引，虽然这个字段的区分度不高，但是一般来说，这张表中，SUCCESS 的数据量占 90%，而 INIT 的数据量只占 10%，而我们扫表的时候只关心 INIT 即可，所以增加索引后，扫表的效率是可以大大提升的。

其次，可以考虑多线程并发扫表，这里可以考虑采用线程池，在任务中开多个线程并发的从数据库中扫描数据进行处理。

但是这样做，会带来一个问题，那就是多个线程之间如何做好隔离，如何确保不会出现并发导致同一条记录被多个线程执行多次呢？

首先最基本的保障，扫表之后的处理逻辑要做好幂等控制，一旦出现了重复的情况，下游也能因为做了幂等而不会重复处理。

除此以外，在扫表的时候，可以通过分段的思想进行数据隔离。举个例子：

```java
Long minId = messageService.getMinInitId();


for(int i=1;i<= threadPool.size();i++){
    Long maxId = minId + segmentSize()*i;

    List<Message> messages = messageService.scanInitMessages(minId,maxId);

    proccee(messages);
    minId = maxId + 1;
}
```

像上面的例子中，假设有 10 个线程，那么第一个线程就扫描 ID 处于 0-1000 的数据，第二个线程扫描 1001-2000 的数据，第三个线程扫描 2001-3000 的数据。这样以此类推，线程之间通过分段的方式就做好了隔离，可以避免同一个数据被多个线程扫描到。

这个做法，有个小问题，那就是 INIT 的数据的 ID 可能不是连续的，那么就需要考虑其他的分段方式，比如在时间表中增加一个业务 ID，然后根据这个 biz_id 做分片也可以。

比如：

```java
for(int i=1;i<= threadPool.size();i++){
    List<Message> messages = messageService.scanInitMessages(i);
    proccee(messages);
}
```

这样在SQL中：

```java
SELECT * FROM RETRY_MESSAGE WHERE 
STATE = "INIT"
AND BIZ_ID LIKE "${frontNumber}%"
```

那么，不同的线程执行的SQL就不一样了分别是：

```java
SELECT * FROM RETRY_MESSAGE WHERE 
STATE = "INIT"
AND BIZ_ID LIKE "1%"

SELECT * FROM RETRY_MESSAGE WHERE 
STATE = "INIT"
AND BIZ_ID LIKE "2%"

SELECT * FROM RETRY_MESSAGE WHERE 
STATE = "INIT"
AND BIZ_ID LIKE "3%"

SELECT * FROM RETRY_MESSAGE WHERE 
STATE = "INIT"
AND BIZ_ID LIKE "4%"
```

这样也是可以做分段的。



**集中式扫表会影响正常业务**

如果业务量比较大的话，集中式的扫描数据库势必给数据库带来一定的压力，那么就会影响到正常的业务。

> 因为数据量大的话会一直扫表做查询，数据量大的时候查询就会很慢，那么数据库连接数就会被占满。导致应用的正常请求拿不到连接.

那么想要解决这个问题，首先可以考虑，不扫主库，而是扫描备库。之所以能这么做，是因为这个业务场景一般都是可以接受一定的数据延迟的，那么备库带来延迟就可以忽略，但是备库是没有业务操作的，所以对备库的扫描是不会对业务造成影响的。

当然，这里还要考虑一个问题，那就是备库扫描数据之后的执行，执行完该如何同步到主库，这里可以直接修改主库，主备库数据ID 一致的，直接去修改主库的就行了。不建议直接在备库上修改。

但是不管怎么样，备库还是可以分担扫表的这个大量高峰请求的。

除了扫备库，还有一个方案，那就是做分库了。把原来集中在同一个数据库的数据分散到不同的数据库中，这样用集群代替单库来整体对外提供服务，可以大大的提升吞吐量。

因为多个数据库的话，每个库提供的连接数就会多，并且多个实例的话，CPU、IO、LOAD 这些指标也可以互相分担。



**定时扫表存在延迟问题**

定时任务都是集中式的定时执行的，那么就会存在延迟的问题。随着数据库越来越大，延时会越来越长。

想要降低延迟，那就要抛弃定时任务的方案，可以考虑延迟消息，基于延迟消息来做定时执行。

用了延迟消息之后，还可以缓解数据库的压力。也能比定时扫表的性能要好，实时性也更高。



**同步转异步**

再提一个方案，那就是同步转异步。什么叫同步转异步呢，那就是同步先干一把，失败了的话，再异步执行。如：

```java
private static ThreadFactory namedThreadFactory = new ThreadFactoryBuilder()
    .setNameFormat("hollis-pool-%d").build();

private static ExecutorService pool = new ThreadPoolExecutor(5, 200,
    0L, TimeUnit.MILLISECONDS,
    new LinkedBlockingQueue<Runnable>(1024), namedThreadFactory, new ThreadPoolExecutor.AbortPolicy());

@Transactional(rollbackFor = Exception.class)
public void pay(PayRequest payRequest){

	//在同一个事务中做本地业务操作和记录消息
	payService.doPay(payRequest);
    retryMessageService.init(payRequest);

	//同步执行一次外部调用
    try{
        Result result = outerService.doSth(payRequest);
        if(result.isSuccess()){
            retryMessageService.success(payRequest);
        }
    }catch(Exception e){
        // 捕获异常，失败依赖异步重试
    }
}
```

如上，在同步接口中，先尝试着执行一次要可能会失败的任务，如果成功了，那就把事件推进到成功，如果失败了也无所谓，因为会有异步定时任务捞起来重试。

当然，这个方案在本地事务中做了远程调用，会拖长事务，不太建议，这里建议考虑用 SpringEvent 的异步事件来实现。

#### 什么是Canal，他的工作原理是什么？

Canal 是阿里巴巴开源的数据同步工具，他是一个用于数据库的数据变更捕获，它可以捕获数据库中的变更操作（如插入、更新、删除），并将这些变更以实时流的方式发布给其他系统进行消费。主要应用场景之一是数据库的增量数据同步，通常在数据仓库、缓存、搜索引擎等系统中使用。

我们经常会在数据迁移、数据同步的场景中需要用到 canal，比如分库分表时买家表同步出一张卖家表来，比如我们要把 mysql 中的数据同步到 es 中等等，这些场景，canal 都能大显神威。

Canal的实现原理其实挺简单的：

Canal会模拟 MySQL slave 的交互协议，把自己伪装成为一个 MySQL slave ，向 MySQL master 发送dump 协议，MySQL master 收到 dump 请求后，会被这个伪装的 slave ( canal )拉取这些 binlog ，canal 把 binlog 解析成流，然后对接到各个后续的消费者中，如 ES、数据库等。

#### 什么是分布式系统的一致性？

所谓一致性，是指数据在多个副本之间是否能够保持一致的特性。再聊一致性的时候，其实要搞清楚一致性模型。（概念挺多，但是没办法，这玩意它本身就是理论。想结合代码、示例都做不到，甚至想着画个图都不知道该如何下手）

分布式系统中的一致性模型是一组管理分布式系统行为的规则。它决定了在分布式系统中如何访问和更新数据，以及如何将这些更新提供给客户端。面对网络延迟和局部故障等分布式计算难题，分布式系统的一致性模型对保证系统的一致性和可靠性起着关键作用。在分布式系统中有多种一致性模型可用，每个模型都有其优点和缺点，选择模型取决于系统的具体要求。

大的分类上面，主要有三种，分别是**强一致性**、**弱一致性**和**最终一致性**：

- 强一致性模型（Strong Consistency）： 在强一致性模型下，系统保证每个读操作都将返回最近的写操作的结果，即任何时间点，客户端都将看到相同的数据视图。这包括线性一致性（Linearizability）、顺序一致性（Sequential Consistency）和严格可串行性（Strict Serializability）等子模型。强一致性模型通常牺牲了可用性来实现数据一致性。

- 弱一致性模型（Weak Consistency）： 弱一致性模型放宽了一致性保证，它允许在不同节点之间的数据访问之间存在一定程度的不一致性，以换取更高的性能和可用性。这包括因果一致性（Causal Consistency）、会话一致性（Session Consistency）和单调一致性（Monotonic Consistency）等子模型。弱一致性模型通常更注重可用性，允许一定程度的数据不一致性。

- 最终一致性模型（Eventual Consistency）： 最终一致性模型是一种最大程度放宽了一致性要求的模型。它允许在系统发生分区或网络故障后，经过一段时间，系统将最终达到一致状态。这个模型在某些情况下提供了很高的可用性，但在一段时间内可能会出现数据不一致的情况。



**线性一致性 & 顺序一致性**

线性一致性（Linearizability）和顺序一致性（Sequential Consistency）是两种强一致性模型。

**线性一致性是一种最强的一致性模型，它强调在分布式系统中的任何时间点，读操作都应该返回最近的写操作的结果。**

举个例子，如果操作A在操作B之前成功完成，那么操作B在序列化中应该看起来在操作A之后发生，即操作A应该在操作B之前完成。**线性一致性强调实时性，确保操作在实际时间上的顺序保持一致。**

**顺序一致性也是一种强一致性模型，但相对于线性一致性而言，它放宽了一些限制。**在顺序一致性模型中，系统维护一个全局的操作顺序，以确保每个客户端看到的操作顺序都是一致的。

**与线性一致性不同，顺序一致性不强调实时性，只要操作的顺序是一致的，就可以接受一些延迟。**

他们的主要区别在于强调**实时性**。线性一致性要求操作在实际时间上的顺序保持一致，而顺序一致性只要求操作的顺序是一致的，但不一定要求操作的实际时间顺序。



**顺序一致性 & 最终一致性**

很多人看完线性一致性和顺序一致性的区别之后，会容易懵，看上去顺序一致性和我们理解的最终一致性有点像？

那么他们的区别是啥呢？

在时间上，虽然顺序一致性和最终一致性都不强要求实时性，但是最终一致性的时间放的会更宽。并且最终一致性其实并不强调顺序，他只需要保证最终的结果一致就行了，而顺序一致性要求操作顺序必须一致。

并且，顺序一致性还是一种强一致性，比如在 Zookeeper 中，其实就是通过 ZAB 算法来保证的顺序一致性，即各个节点之间的写入顺序要求一致。并且要半数以上的节点写入成功才算成功。所以，顺序一致性的典型应用场景就是数据库管理系统以及分布式系统。

而最终一致性通常适用于互联网三高架构的业务开发，如电商网站，社交媒体网站等。



#### 什么是分布式数据库，有什么优势？

分布式数据库，即所谓的 NewSQL。主要代表 TiDB（pingcap）、OceanBase（蚂蚁）、Spanner（google）。与传统关系型数据库相比：

1. 性能高：在亿级别以上，读和写都会高于传统关系型数据库（MySQL、SQLServer等），在亿级别以下略逊色与传统关系型数据库
2. 可维护性：TiDB、OceanBase 都以开源的形式存在，其生态也比较贴近于现代数据库的需求（如完全支持云原生），有较好的社区文档、企业免费的培训课程
3. 可靠性：由于分布式的特性，通过副本冗余的方式提升整个集群可靠性。同样由于分布式的特性，无法严格且完全的实现真正意义上的 ACID，从事务的角度来看可靠性降低了。
4. 可扩展性：分布式的特性就在于近乎无限的水平可扩展，增加集群节点数量可大幅度提高集群的 QPS 和存储能力。Spanner 甚至实现了全球部署。
5. 用户体验：兼容大部分 SQL 标准，但也是由于分布式的原因，很多传统关系型数据库的特性（SQL 语法、其他功能）无法支持，如：无法保证自增 id 的连续性，有限的支持事务的强一致性(对性能略有损失)，天生分布式不支持单机部署（小型业务无法使用）。TiDB 与 MySQL 思想类似，也存在存储引擎概念，通过存储引起实现了 OLAP 和 OLTP 两种模式，插入数据能随时进行在线事务操作，也可以进行实时的离线分析操作。

#### 有了 MySQL 为啥还要有分布式数据库？

其实能用上分布式数据库的公司数据量和 QPS 已经非常庞大了。很难通过 MySQ L解决数据量和高 QPS 的问题了。

MySQL 在应对大数据量的时候通过采用分库分表的方案，应对大量读 QPS 的场景方案是进行读写分离，而写 TPS 很难提高，分库分表会带来诸多问题。

读写分离会带来的问题：

1. 主从复制存在延迟，存在写后读依赖的场景，只能强制读主，进而对主产生了压力
2. 读写分离需要应用感知主和从的存在
3. 使用 cluster 方案维护主从切换成本高
4. 纯主从复制方案单实例写 tps 有限，从只能提高读的并发度

因此，MySQL 官方提供了 Cluster 方案，但对主从选举时采用了复杂的 paxos 算法，可维护性和性能都大幅度降低，业内并不买账，依旧使用传统的分库分表、主从复制。

总的来说 MySQL 可维护性和可扩展性较差。

在分布式数据库中，**从 TiDB 来说，重点解决了可维护性和可扩展性的问题**。

TiDB 通过 pd 节点管理数据的自动分片，调度，倾斜自动迁移，热点自动迁移，自动选主（采用轻量的raft协议）等功能。数据节点单机使用 LSM 树作为底层存储结构，大幅度提升机械磁盘写的 IOPS。

本质上内部分片采用范围分片的策略，然后整个集群构成了一个树状结构，进行聚合，分页查询。分布式中时间是一个很重要的东西，无论是事务的 id 生成，还是 MVCC（多版本并发控制）都依托于时间，在计算机中即使是采用 NTP 服务也无法解决时间漂移的问题。

TiDB 通过 pd 节点管理时间，计算节点、数据节点都从pd节点进行同步。而 Spanner 采用了一个硬件设备（艳原子钟）确保数据中心的时间非常精准，从而实现了全球数据库部署，即跨国际的时间同步策略保证了事务的正确。

由于是分布式数据库，有限支持 id 自增，有限支持强一致的事务(对性能略有损失)。其弊端：

1. 天生分布式，不支持单机部署，基本不适合小业务量的应用
2. 由于分布式，事务隔离级别弱，无法完全实现 ACID
3. 实测在亿级以下的读写请求比 mysql 的性能略低一些

总的来说，虽然 tidb 承诺金融级别的分布式数据库，但是选择用在核心链路上还要深思熟虑。用在支付链路上曾遇到过因为 tidb 慢查询导致整个集群崩溃，其原因是 tidb 查询分析器有 bug 导致选择错了查询计划。

分布式数据库是技术和商业发展的必然，人类产生的数据量越来越大，传统关系型数据库也在逐渐往分布式数据库上过度（如 MySQL 的 Cluster 方案），人们应该逐渐接受分布式带来的问题，接受并能够解决事务不是那么强一致。

#### 如何基于 MQ 实现分布式事务?

在分布式事务的实现中，有很多种方案，其中比较常用的就是基于 MQ 来实现，在 MQ 的具体实现中，又有很多种具体的方案，从大的方面来说可以分为两种：

- 可靠消息最终一致性
- 最大努力通知

**可靠消息最终一致性**

可靠消息最终一致性，顾名思义就是依赖可靠的消息，来实现一种最终一致性的模型。

他的大致流程就是：
1、事务的发起方执行本地事务
2、事务的发起方向事务的参与方发送MQ消息
3、事务的参与方接收到MQ消息后执行自己的本地事务

这里面事务的发起方和参与方都需要各自执行本地事务，他们之间，通过可靠消息来保障最终一致。

那么，怎么样的消息算可靠呢，直接依赖 kafka、rocketMQ 发送一个消息就可靠了么？显然是不行的，因为我们知道，在出现网络分区、网络延迟等情况时，是没办法保证消息一定可以发出去的，也没办法保证消息发出去就一定能被成功消费。

那么想要做到让这个消息可靠，一般由两种做法：

1、本地消息表

2、事务消息

> 通过这两种方案，都可以保证事务的发起方在执行完本地事务之后，消息一定可以发出去，并且一定能被消费成功。
>
> 本地消息表的方案是基于本地事务+重试，来保证 MQ 消息一定可以发出去。
> 事务消息的方案是基于 MQ 的事务消息机制，把一条消息拆成两个 half 消息，通过 2 阶段的方式 + 回调反查来保证消息一定能发出去。
>
> 2 者都是依赖 MQ 自身的重试机制 + 事务参与者反查 + 对账来保证消息一定可以消费。

**最大努力通知**

除了可靠消息最终一致性这种以外，还有一种方式就是也使用消息，但是这个消息并不要求一定可靠。这就是最大努力通知。

这个方案一般就是只依赖重试机制，来做最大努力的通知事务参与者。但是需要注意的是，在最大努力通知的过程中，可能会出现消息重复发送的情况，也可能会出现消息丢失的情况。

> 【只用消息为啥不行】
>
> 直接用 MQ 发消息为啥不可以呢，要搞本地消息表、事务消息等这么麻烦的方案呢？
>
> 主要有几个问题：
>
> 1、消息不可靠，不管是啥 MQ，都没有办法保证 100% 的消息不丢的。所以，完全依赖消息是可能会丢消息的。
>
> 2、发消息和本地事务没办法保证一致性。我们在一个本地事务的操作和一个 MQ 发送操作，这俩保证不了一致性，有可能一个成功一个失败。比如，本地事务提交了，MQ 发失败了。或者本地事务回滚了，MQ 发成功了。都会导致最终的数据不一致。
>
> 本地事务提交了，MQ 发失败了？
>
> 如果没有把 MQ 放到事务中，那么就会出现这种情况，导致 MQ 丢失。
>
> 本地事务回滚了，MQ 发成功了？
>
> 当我们把 MQ 的发送也放到本地事务中的时候，一旦 MQ 发失败了，本地事务会回滚。但是问题是 MQ 有可能其实真正的是成功了，因为网络延迟等情况，他返回了失败，那这时候，就出现了不一致的情况。

#### 最大努力通知&事务消息&本地消息表三者区别是什么？

最大努力通知、MQ事务消息以及本地消息表都是依赖MQ实现最终一致性的方案。其中本地消息表和MQ事务消息其实是可靠消息最终一致性的两种具体实现。

这三者中，方案最简单的肯定是最大努力通知，因为他不需要保证消费者一定能接收到，只是尽自己最大的努力去通知就行了。最多就是在发消息的地方加一个重试的机制。

但是这个方案缺点也很明显，那就是可能会导致消息的重复和丢失，这个比较容易理解。

虽然最大努力通知也是一种最终一致性的方案，但是他的一致性保障并没有那么强，所以他不适合用在一些一致性要求较高的场景。只适合用在消息丢了也无所谓的场景。比如说下单后邮件通知、开通后发送欢迎短信之类的业务场景。

MQ事务消息以及本地消息表这两个方案一致性要求更高一些，但是同样方案也要更复杂一些。

MQ事务消息的方案首先要求这个MQ是支持事务消息的，其次对业务代码有侵入性，因为本来只需要发一次消息，用了这个方案之后需要改成发送两个half消息，并且同时还得给MQ提供一个反查的接口。

本地消息表这个方案对代码的侵入性没那么高，并且不需要MQ支持事务消息，但是他需要单独创建一张本地消息表，并且还需要提供一个定时任务来做轮询。所以他的改造成本也不低。

一般来说，事务消息和本地消息表比较适合于对一致性要求没那么高，不要求强一致，但是也不能丢的一些场景，比如用户下单后给用户增加积分。

一般来说，事务消息和本地消息表两个方案是可以互相替换的，用了事务消息的地方都可以换成本地消息表。但是实际来说，如果MQ支持事务消息，那么可以考虑这个方案，如果公司使用的MQ不支持事务消息，那么就可以考虑本地消息表。

或者还有些场景有一些消息持久化、或者对账的需求，那么也建议使用本地消息表的方案。

#### 锁和分布式锁的核心区别是什么？

锁和分布式锁的核心区别主要在于作用范围和适用场景。

锁，我们常用的就是 synchronized，ReentrantLock 等，他们通常是在单个进程内起作用的同步机制，用于控制对共享资源的访问。多个线程或进程之间可以使用锁来确保对关键资源的互斥访问。

这种锁，主要适用于单体应用，确保在同一JVM进程内多个线程同步共享资源的访问。

分布式锁，作用范围更广泛，可以跨越多个计算机或多个进程，用于协调分布式系统中的不同节点，以确保在全局范围内对共享资源的互斥访问。

分布式锁适用于分布式系统中，各个节点之间需要协调共享资源访问的情况。在分布式环境中，传统的锁机制可能无法有效地处理多节点之间的同步问题，因此需要分布式锁来确保一致性。

所以，普通的锁主要用于单机环境，用于控制同一JVM进程中多个线程对共享资源的互斥访问。而分布式锁则适用于分布式环境，用于协调多个计算机或多个进程之间对共享资源的互斥访问，确保分布式系统的一致性。

#### TCC 是强一致性还是最终一致性？

TCC 的过程是：

- Try 阶段：尝试执行所有操作，并锁定所需资源以准备提交。
- Confirm 阶段：如果所有的 Try 操作成功，那么执行 Confirm 操作，最终提交事务。
- Cancel 阶段：如果任何 Try 操作失败，或者确认过程中遇到问题，执行 Cancel 操作来回滚所有的操作，释放锁定的资源。

通过他这个通过精心设计的流程，你就能看得出他的设计尽可能确保数据的一致性。

在理想情况下，如果所有参与组件都能正确执行其 Try、Confirm 和 Cancel 逻辑，并且系统之间的通信是可靠的，那么 TCC 是可以提供强一致性的。

但是，如果你想让 TCC 需要所有参与的服务或组件必须能够正确处理 Try、Confirm 和 Cancel 各阶段的逻辑。在分布式系统中，因为网络延迟、服务中断或其他外部因素登的影响，这几乎是不可能的。

所以，因为在调用 confirm 或 cancel 的时候也可能因为某种原因（比如网络延迟）导致调用失败，就需要通过重试等方式来解决，这个过程就会出现短暂的不一致。最终再通过重试、人工介入等手段来保证他能达到最终一致性。

> 所以，TCC 模式的设计初衷是提供强一致性的。然而，在实际操作中，因为存在着各种各样的实际问题，如网络延迟等，这就使得它不得不降级为最终一致性。因此，虽然 TCC 旨在实现强一致性，但在某些实际应用场景中，它可能表现为介于强一致性和最终一致性之间。

